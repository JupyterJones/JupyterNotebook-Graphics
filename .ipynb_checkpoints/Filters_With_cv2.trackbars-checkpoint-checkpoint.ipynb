{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-09-07 15:50:07--  https://upload.wikimedia.org/wikipedia/en/b/b0/Black_%26_White_Handshake_-_Still_from_the_film_Colour_Blind_%282009%29.JPG\n",
      "Resolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\n",
      "Connecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 984753 (962K) [image/jpeg]\n",
      "Saving to: ‘images/testimage.jpg’\n",
      "\n",
      "images/testimage.jp 100%[===================>] 961.67K   177KB/s    in 6.0s    \n",
      "\n",
      "2018-09-07 15:50:13 (160 KB/s) - ‘images/testimage.jpg’ saved [984753/984753]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O images/testimage.jpg https://upload.wikimedia.org/wikipedia/en/b/b0/Black_%26_White_Handshake_-_Still_from_the_film_Colour_Blind_%282009%29.JPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unichr(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Getch(object):\n",
    "    \"\"\"Gets a single character from standard input.  \n",
    "       Does not echo to the screen.\"\"\"\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            self.impl = _GetchWindows()\n",
    "        except ImportError:\n",
    "            self.impl = _GetchUnix()\n",
    "\n",
    "    def __call__(self): \n",
    "        return self.impl()\n",
    "\n",
    "class _GetchUnix(object):\n",
    "    def __init__(self):\n",
    "        import tty, sys\n",
    "\n",
    "    def __call__(self):\n",
    "        import sys, tty, termios\n",
    "        fd = sys.stdin.fileno()\n",
    "        old_settings = termios.tcgetattr(fd)\n",
    "        try:\n",
    "            tty.setraw(sys.stdin.fileno())\n",
    "            ch = sys.stdin.read(1)\n",
    "        finally:\n",
    "            termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)\n",
    "        return ch\n",
    "\n",
    "\n",
    "class _GetchWindows(object):\n",
    "    def __init__(self):\n",
    "        import msvcrt\n",
    "\n",
    "    def __call__(self):\n",
    "        import msvcrt\n",
    "        return msvcrt.getch()\n",
    "\n",
    "\n",
    "getch = _Getch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-eeb589b849bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/testimage.jpg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load a dummy image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# Esc key to stop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('images/testimage.jpg') # load a dummy image\n",
    "while(1):\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(33)\n",
    "    if k==27:    # Esc key to stop\n",
    "        break\n",
    "    elif k==-1:  # normally -1 returned,so don't print it\n",
    "        continue\n",
    "    else:\n",
    "        print k # else print its value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Capture an image - not video - to work with\n",
    "import cv2\n",
    "from cv2 import *\n",
    "# initialize the camera\n",
    "cam = VideoCapture(0)   # 0 -> index of camera\n",
    "s, img = cam.read()\n",
    "if s:    # frame captured without any errors\n",
    "    namedWindow(\"cam-test\",WINDOW_AUTOSIZE)\n",
    "    imshow(\"cam-test\",img)\n",
    "    waitKey(0)\n",
    "    \n",
    "    while 1:\n",
    "    # exit on ESC key\n",
    "    k = cv2.waitKey(0)\n",
    "    if k == 27:\n",
    "        \n",
    "        if k == 27:\n",
    "        break\n",
    "     \n",
    "    \n",
    "    destroyWindow(\"cam-test\")\n",
    "    cv2.imwrite(\"images/webcam8.jpg\",img) #save image\n",
    "\n",
    "cam.release() \n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import modules\n",
    "import sys  \n",
    "import os\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "# Open image\n",
    "ima = Image.open(\"images/webcam8.jpg\")\n",
    "\n",
    "# Create an enhancer object\n",
    "enhancer = ImageEnhance.Sharpness(ima)\n",
    "\n",
    "# Apply a level of enhancment\n",
    "factor_rd = enhancer.enhance(2.8)\n",
    "\n",
    "# Show results 'factor_rd'\n",
    "factor_rd.show(\"ImageEnhance\", factor_rd)\n",
    "\n",
    "# Show original 'ima'\n",
    "ima.show(\"Orig\", ima)\n",
    "\n",
    "# Save enhanced Image\n",
    "factor_rd.save(\"images/ImageEnhance-webcam8-1.8.jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "me = Image.open('images/ImageEnhance-webcam8-1.8.jpg')\n",
    "print me.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "me = Image.open('images/ImageEnhance-webcam8-1.8.jpg')\n",
    "width, height = me.size\n",
    "leftIn = 100\n",
    "lefttop = 20\n",
    "RightIn = width-leftIn\n",
    "RightBottom = 460\n",
    "imCrop = leftIn,lefttop,RightIn,RightBottom\n",
    "#crop \n",
    "cropim = me.crop(imCrop)\n",
    "#me.crop(ul, lr)\n",
    "#me\n",
    "print imCrop\n",
    "cropim.save(\"images/webcam-crop.jpg\")\n",
    "cropim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check image size\n",
    "from PIL import Image\n",
    "iop = Image.open(\"images/webcam-crop.jpg\")\n",
    "print iop.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add 10 Pixel 'white' Border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import ImageOps\n",
    "wboder = 5\n",
    "ImageOps.expand(Image.open('images/webcam-crop.jpg'),border=wboder,fill='black').save('images/webcam-border.jpg')\n",
    "view = Image.open('images/webcam-border.jpg')\n",
    "#view.show(\"Orig\", view)\n",
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Image Blur and Canny Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply Image Blur and Canny Edge\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "def nothing(x):\n",
    "    pass\n",
    "cv2.namedWindow('canny_edge', True)\n",
    "img_noblur = cv2.imread('images/webcam-border.png', 0)\n",
    "img = cv2.blur(img_noblur, (7,7))\n",
    " \n",
    "#canny_edge = cv2.Canny(img, 0, 0)\n",
    " \n",
    "#cv2.imshow('image', img)\n",
    "#cv2.imshow('canny_edge', canny_edge)\n",
    "while(1):\n",
    "    \n",
    "    cv2.createTrackbar('min_value','canny_edge',0,500,nothing)\n",
    "    cv2.createTrackbar('max_value','canny_edge',0,500,nothing)\n",
    "\n",
    "\n",
    "\n",
    "    min_value = cv2.getTrackbarPos('min_value', 'canny_edge')\n",
    "    max_value = cv2.getTrackbarPos('max_value', 'canny_edge')\n",
    "\n",
    "    canny_edge = cv2.Canny(img, min_value, max_value)\n",
    "    cv2.imshow('images/image', img)\n",
    "    cv2.imshow('images/canny_edge', canny_edge)    \n",
    "\n",
    "    #print ilowH, ilowS, ilowV\n",
    "    if(cv2.waitKey(True) & 0xFF == ord('q')):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"images/webcam-border.png\")\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# Blur parameters must be an ODD number\n",
    "# GaussianBlur removes the small artifacts\n",
    "blur = cv2.GaussianBlur(gray,(11,11),0)\n",
    "\n",
    "#circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 300, np.array([]), 10, 30, 60, 300)\n",
    "#circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1, 300, np.array([]), 5, 5, 100, 100)\n",
    "ret,thresh1 = cv2.threshold(blur,127,255,cv2.THRESH_BINARY)\n",
    "edges = cv2.Canny(thresh1, 100,200)\n",
    "imagem = cv2.bitwise_not(edges)\n",
    "\n",
    "result = cv2.bitwise_and(image,image, mask=imagem)\n",
    "\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0,:]:\n",
    "        cv2.circle(image, (i[0], i[1]), i[2], (0, 255, 0), 1)\n",
    "        cv2.circle(image, (i[0], i[1]), 2, (0, 0, 255), 3)\n",
    "\n",
    "cv2.imshow(\"Blur\", blur)\n",
    "#cv2.imshow(\"Circled\", circles)\n",
    "cv2.imshow(\"Thresh\", thresh1)\n",
    "cv2.imshow(\"edges\", edges)\n",
    "cv2.imshow(\"imagem\", imagem)\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.imshow(\"Result\", result)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"images/webcam-border.png\")\n",
    "#image = cv2.imread(\"images/webcam-border.png\", 0)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#blur = cv2.GaussianBlur(gray,(9,9),0)\n",
    "\n",
    "#circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 300, np.array([]), 10, 30, 60, 300)\n",
    "circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 300, np.array([]), 5, 5, 100, 100)\n",
    "ret,thresh1 = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)\n",
    "edges = cv2.Canny(thresh1, 100,200)\n",
    "imagem = cv2.bitwise_not(edges)\n",
    "\n",
    "res = cv2.bitwise_and(image,image, mask=imagem)\n",
    "\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0,:]:\n",
    "        cv2.circle(image, (i[0], i[1]), i[2], (0, 255, 0), 1)\n",
    "        cv2.circle(image, (i[0], i[1]), 2, (0, 0, 255), 3)\n",
    "\n",
    "#cv2.imshow(\"Circled\", image)\n",
    "#cv2.imshow(\"Thresh\", thresh1)\n",
    "#cv2.imshow(\"edges\", edges)\n",
    "cv2.imshow(\"imagem\", imagem)\n",
    "cv2.imshow(\"res\", res)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "from cv2 import *\n",
    "picture = Image.new( 'RGB', (150,150), \"black\")\n",
    "\n",
    "# Get the size of the image\n",
    "width, height = picture.size\n",
    "# Get the size of the image\n",
    "for x in range(0, width - 1):\n",
    "     for y in range(0, height - 1):\n",
    "        \n",
    "        while (h<x):\n",
    "            while (v <y):\n",
    "\n",
    "                if (cx + cy < 100):\n",
    "                    new_color = (0,0,255)\n",
    "                    else:\n",
    "                    new_color = (0,0,0) \n",
    "                    v=v+1\n",
    "                    else:    \n",
    "                    h=h+1\n",
    "                    v=0        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    picture.putpixel( (x,y), new_color)\n",
    "                    picture.save(\"images/new_color-blackk.jpg\")\n",
    "                    #!showme images/new_color-face_300.jpg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "from cv2 import *\n",
    "from math import cos\n",
    "picture = Image.new( 'RGB', (200,200), \"white\")\n",
    "\n",
    "c=10\n",
    "# Get the size of the image\n",
    "width, height = picture.size\n",
    "fx = x-width*-1\n",
    "fy = y-height*-1\n",
    "# Get the size of the image\n",
    "for x in range(0, width - 1):\n",
    "     for y in range(0, height - 1):\n",
    "        fx = x-width*-1\n",
    "        fy = y-height*-1\n",
    "        color = picture.getpixel((x, y))\n",
    "        if (cos(x+y) <2):\n",
    "            k = abs(cos(fx+fy)*fx)\n",
    "            c = int(k)\n",
    "            k1 = abs(fx**2-fy**2)\n",
    "            c1 = int(k)\n",
    "            #c = (abs(cos(fx)*fy**2*.01)\n",
    "            new_color = (c,c1,0)\n",
    "        else:\n",
    "            new_color = (0,c1,c)\n",
    "            \n",
    "            print c,c1, cos(x+y)\n",
    "            picture.putpixel( (x,y), new_color)\n",
    "            picture.save(\"images/new_color-black4.jpg\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from cv2 import *\n",
    "\n",
    "picture = Image.new( 'RGB', (5,5), \"black\")\n",
    "# Get the size of the image\n",
    "x, y = picture.size\n",
    "h = x*-1\n",
    "v = y*-1\n",
    "while (h < x):\n",
    "    while (v < y):\n",
    "        #cx = x-(width)\n",
    "        #cy = y-(height)\n",
    "        #if (cx**2 + cy**2 == 0):\n",
    "        #   print x,y\n",
    "        #else:\n",
    "        #   new_color = (0,0,0)\n",
    "        print x,y,h,v\n",
    "        v = v +1    \n",
    "h = h + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!showme images/new_color-black6.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "from cv2 import *\n",
    "from math import cos\n",
    "picture = Image.new( 'RGB', (40,40), \"white\")\n",
    "\n",
    "c=10\n",
    "# Get the size of the image\n",
    "width, height = picture.size\n",
    "#fx = x-width*-1\n",
    "#fy = y-height*-1\n",
    "fx = x-width\n",
    "fy = y-height\n",
    "# Get the size of the image\n",
    "for x in range(0, width - 1):\n",
    "     for y in range(0, height - 1):\n",
    "        fx = int(cos(x-width/2*-1)*10)\n",
    "        fy = y-height/2*-1\n",
    "        color = picture.getpixel((x, y))\n",
    "        if ((fx+fy) < 420):\n",
    "            zz = fy -300\n",
    "            new_color = (fx,zz,0)\n",
    "            picture.putpixel( (x,y), new_color)\n",
    "        else:\n",
    "            vv = int((fx+fy)/2)-50\n",
    "            new_color = (vv,0,fy)\n",
    "            picture.putpixel( (x,y), new_color)\n",
    "            print new_color, fx, zz, vv\n",
    "            \n",
    "            picture.save(\"images/new_color-black6.jpg\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "from cv2 import *\n",
    "from math import cos\n",
    "picture = Image.new( 'RGB', (256,256), \"white\")\n",
    "\n",
    "c=10\n",
    "# Get the size of the image\n",
    "width, height = picture.size\n",
    "#fx = x-width*-1\n",
    "#fy = y-height*-1\n",
    "fx = x-width\n",
    "fy = y-height\n",
    "# Get the size of the image\n",
    "for x in range(0, width - 1):\n",
    "     for y in range(0, height - 1):\n",
    "        fx = x-width/2*-1\n",
    "        fy = y-height/2*-1\n",
    "        color = picture.getpixel((x, y))\n",
    "        if ((x+y) < 0):\n",
    "            \n",
    "            new_color = (fx,fy,0)\n",
    "        else:\n",
    "            new_color = (0,fx,fy)\n",
    "            picture.putpixel( (x,y), new_color)\n",
    "            #print new_color, fx, fy\n",
    "            \n",
    "            picture.save(\"images/new_color-black1.jpg\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "picture.save(\"images/new_color-black.jpg\")\n",
    "#wboder = width+10\n",
    "wboder = 10\n",
    "ImageOps.expand(Image.open('images/new_color-black.jpg'),border=wboder,fill='white').save('images/imaged-with-border.png')\n",
    "!showme images/imaged-with-border.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "ImageOps.expand(picture),border=10,fill=\"white\").save('images/imaged-with-border.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.namedWindow('Creation') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from cv2 import *\n",
    "\n",
    "picture = Image.new( 'RGB', (150,150), \"black\")\n",
    "\n",
    "# Get the size of the image\n",
    "width, height = picture.size\n",
    "# Get the size of the image\n",
    "for x in range(0, width - 1):\n",
    "     for y in range(0, height - 1):\n",
    "        cx = x-(width/2)\n",
    "        cy = y-(height/2)\n",
    "        if (cx**2 + cy**2 == 0):\n",
    "           new_color = (0,0,255)\n",
    "        else:\n",
    "           new_color = (0,0,0)\n",
    "        picture.putpixel( (x,y), new_color)\n",
    "        picture.save(\"images/new_color-black.jpg\")\n",
    "        #!showme images/new_color-face_300.jpg\n",
    "        wboder = 10\n",
    "        ImageOps.expand(Image.open('images/new_color-black.jpg'), border=wboder, fill='white').save('images/imaged-with-border.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from cv2 import *\n",
    "\n",
    "picture = Image.new( 'RGB', (5,5), \"black\")\n",
    "# Get the size of the image\n",
    "x, y = picture.size\n",
    "h = x*-1\n",
    "v = y*-1\n",
    "print h,v,x,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from cv2 import *\n",
    "cv2.namedWindow('BinaryThreshold') \n",
    "height = -50\n",
    "width = -50\n",
    "\n",
    "picture = Image.new( 'RGB', (50,50), \"black\")\n",
    "# Get the size of the image\n",
    "x, y = picture.size\n",
    "h = x*-1\n",
    "v = y*-1\n",
    "\n",
    "\n",
    "while (height < abs(height)):\n",
    "    while (width < abs(width)):\n",
    "        cx = x-(width)\n",
    "        cy = y-(height)\n",
    "        if (cx**2 + cy**2 == 0):\n",
    "           print x,y\n",
    "        else:\n",
    "           new_color = (0,0,0)\n",
    "\n",
    "    width = width +1    \n",
    "height = height + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "testimage = Image.open(\"images/new_color-black.jpg\")\n",
    "w, h = testimage.size\n",
    "print w\n",
    "print h\n",
    "testimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "help(Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "iop = Image.open(\"images/webcam-border.png\")\n",
    "print iop.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sized = iop.resize((450,450), Image.NEAREST)\n",
    "sized.save(\"images/webcam-borderS.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "!showme images/webcam-borderS.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "cropim = sized.crop((130,100,450,330))\n",
    "cropim.save(\"images/cropim.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "cvimg = cv2.imread('images/webcam.jpg',0)\n",
    "ret,thresh1 = cv2.threshold(cvimg,127,255,cv2.THRESH_BINARY)\n",
    "cv2.imwrite(\"images/thresh1.png\", thresh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!showme images/thresh1.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img0 = Image.open(\"images/thresh1.png\")\n",
    "imga = img0.convert(\"RGBA\")\n",
    "imga\n",
    "imga.save(\"images/img0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"images/cropim.png\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.GaussianBlur(gray,(15,15),0)\n",
    "\n",
    "circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 300, np.array([]), 10, 30, 60, 300)\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0,:]:\n",
    "        cv2.circle(image, (i[0], i[1]), i[2], (0, 255, 0), 1)\n",
    "        cv2.circle(image, (i[0], i[1]), 2, (0, 0, 255), 3)\n",
    "\n",
    "cv2.imshow(\"Circled\", image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"images/thresh1.png\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#blur = cv2.GaussianBlur(gray,(9,9),0)\n",
    "\n",
    "#circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 300, np.array([]), 10, 30, 60, 300)\n",
    "circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 300, np.array([]), 5, 5, 100, 100)\n",
    "ret,thresh1 = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)\n",
    "edges = cv2.Canny(thresh1, 100,200)\n",
    "imagem = cv2.bitwise_not(edges)\n",
    "\n",
    "res = cv2.bitwise_and(image,image, mask=imagem)\n",
    "\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0,:]:\n",
    "        cv2.circle(image, (i[0], i[1]), i[2], (0, 255, 0), 1)\n",
    "        cv2.circle(image, (i[0], i[1]), 2, (0, 0, 255), 3)\n",
    "\n",
    "#cv2.imshow(\"Circled\", image)\n",
    "#cv2.imshow(\"Thresh\", thresh1)\n",
    "#cv2.imshow(\"edges\", edges)\n",
    "cv2.imshow(\"imagem\", imagem)\n",
    "cv2.imshow(\"res\", res)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "image = cv2.imread(\"images/webcam-border.jpg\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray,(9,9),0)\n",
    "\n",
    "#circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 300, np.array([]), 10, 30, 60, 300)\n",
    "circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 300, np.array([]), 5, 5, 100, 100)\n",
    "ret,thresh1 = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)\n",
    "edges = cv2.Canny(image, 100,200)\n",
    "imagem = cv2.bitwise_not(edges)\n",
    "\n",
    "#res = cv2.bitwise_and(image,image, mask=imagem)\n",
    "res = cv2.bitwise_and(image,image, mask=thresh1)\n",
    "\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0,:]:\n",
    "        cv2.circle(image, (i[0], i[1]), i[2], (0, 255, 0), 1)\n",
    "        cv2.circle(image, (i[0], i[1]), 2, (0, 0, 255), 3)\n",
    "\n",
    "#cv2.imshow(\"Circled\", image)\n",
    "#cv2.imshow(\"Thresh\", thresh1)\n",
    "cv2.imshow(\"edges\", edges)\n",
    "cv2.imshow(\"imagem\", imagem)\n",
    "cv2.imshow(\"res\", res)\n",
    "\n",
    "cv2.imwrite(\"images/edges-01.png\", edges)\n",
    "cv2.imwrite(\"images/imagem-01.png\", imagem)\n",
    "cv2.imwrite(\"images/res.png-01\", res)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "image = cv2.imread(\"images/webcam-border.jpg\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray,(9,9),0)\n",
    "\n",
    "#circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 300, np.array([]), 10, 30, 60, 300)\n",
    "circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 300, np.array([]), 5, 5, 100, 100)\n",
    "ret,thresh1 = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)\n",
    "edges = cv2.Canny(image, 100,200)\n",
    "imagem = cv2.bitwise_not(edges)\n",
    "\n",
    "#res = cv2.bitwise_and(image,image, mask=imagem)\n",
    "res = cv2.bitwise_and(image,image, mask=thresh1)\n",
    "\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0,:]:\n",
    "        cv2.circle(image, (i[0], i[1]), i[2], (0, 255, 0), 1)\n",
    "        cv2.circle(image, (i[0], i[1]), 2, (0, 0, 255), 3)\n",
    "\n",
    "#cv2.imshow(\"Circled\", image)\n",
    "#cv2.imshow(\"Thresh\", thresh1)\n",
    "cv2.imshow(\"edges\", edges)\n",
    "cv2.imshow(\"imagem\", imagem)\n",
    "cv2.imshow(\"res\", res)\n",
    "\n",
    "cv2.imwrite(\"images/edges-01.png\", edges)\n",
    "cv2.imwrite(\"images/imagem-01.png\", imagem)\n",
    "cv2.imwrite(\"images/res.png-01\", res)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "def nothing(x):\n",
    "    pass\n",
    "cv2.namedWindow('canny_edge') \n",
    "img_noblur = cv2.imread('images/webcam-border.jpg', 0)\n",
    "img = cv2.blur(img_noblur, (7,7))\n",
    "min_value = 0\n",
    "max_value = 500\n",
    "\n",
    "cv2.createTrackbar('min_value','canny_edge',0,500,nothing)\n",
    "cv2.createTrackbar('max_value','canny_edge',0,500,nothing)\n",
    "while 1:\n",
    "    # exit on ESC key\n",
    "    k = cv2.waitKey(0)\n",
    "    if k == 27:\n",
    "        break\n",
    "     \n",
    "    min_value = cv2.getTrackbarPos('min_value', 'canny_edge')\n",
    "    max_value = cv2.getTrackbarPos('max_value', 'canny_edge')\n",
    "\n",
    "    canny_edge = cv2.Canny(img, min_value, max_value)\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.imshow('canny_edge', canny_edge)    \n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 64\n",
      "threshold 74\n",
      "threshold 90\n",
      "threshold 106\n",
      "threshold 115\n",
      "threshold 122\n",
      "threshold 129\n",
      "threshold 130\n",
      "threshold 133\n",
      "threshold 137\n",
      "threshold 140\n",
      "threshold 145\n",
      "threshold 151\n",
      "threshold 158\n",
      "threshold 163\n",
      "threshold 167\n",
      "threshold 173\n",
      "threshold 180\n",
      "threshold 184\n",
      "threshold 185\n",
      "threshold 188\n",
      "threshold 191\n",
      "threshold 192\n",
      "threshold 185\n",
      "threshold 178\n",
      "threshold 166\n",
      "threshold 155\n",
      "threshold 149\n",
      "threshold 141\n",
      "threshold 138\n",
      "threshold 134\n",
      "threshold 132\n",
      "threshold 128\n",
      "threshold 125\n",
      "threshold 122\n",
      "threshold 119\n",
      "threshold 118\n",
      "threshold 114\n",
      "threshold 108\n",
      "threshold 103\n",
      "threshold 90\n",
      "threshold 81\n",
      "threshold 77\n",
      "threshold 75\n",
      "threshold 74\n",
      "gaussian blur kernel size 4\n",
      "gaussian blur kernel size 6\n",
      "gaussian blur kernel size 9\n",
      "gaussian blur kernel size 10\n",
      "gaussian blur kernel size 12\n",
      "gaussian blur kernel size 14\n",
      "gaussian blur kernel size 15\n",
      "gaussian blur kernel size 14\n",
      "gaussian blur kernel size 13\n",
      "gaussian blur kernel size 12\n",
      "gaussian blur kernel size 11\n",
      "gaussian blur kernel size 10\n",
      "gaussian blur kernel size 9\n",
      "gaussian blur kernel size 8\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/feedstock_root/build_artefacts/opencv_1495334243082/work/opencv-3.2.0/modules/imgproc/src/smooth.cpp:2098: error: (-215) ksize.width > 0 && ksize.width % 2 == 1 && ksize.height > 0 && ksize.height % 2 == 1 in function createGaussianKernels\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-566ef42359d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Gaussian Blur ( x2 +1 = in order to provide odd number for kernel size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mkernelSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTrackbarPos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gaussian blur'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'processed'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mblur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernelSize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernelSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblur\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTrackbarPos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'threshold'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'processed'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /feedstock_root/build_artefacts/opencv_1495334243082/work/opencv-3.2.0/modules/imgproc/src/smooth.cpp:2098: error: (-215) ksize.width > 0 && ksize.width % 2 == 1 && ksize.height > 0 && ksize.height % 2 == 1 in function createGaussianKernels\n"
     ]
    }
   ],
   "source": [
    "# In progress\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "#img_noblur = cv2.imread('images/webcam.jpg', 0)\n",
    "#img = cv2.blur(img_noblur, (7,7))\n",
    "#img = cv2.imread(\"images/webcam-border.jpg\", 0)\n",
    "img = cv2.imread(\"images/webcam-border.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray,(9,9),0)\n",
    "\n",
    "\n",
    "# slider callbacks\n",
    "def printThreshold(x):\n",
    "    print \"threshold\",x\n",
    "def printGaussianBlur(x):\n",
    "    print \"gaussian blur kernel size\",x\n",
    "# make a window to add sliders/preview to\n",
    "cv2.namedWindow('processed')\n",
    "#make some sliders\n",
    "cv2.createTrackbar('threshold','processed',60,255,printThreshold)\n",
    "cv2.createTrackbar('gaussian blur','processed',3,20,printGaussianBlur)\n",
    "# load image\n",
    "\n",
    "# continously process for quick feedback\n",
    "while 1:\n",
    "    # exit on ESC key\n",
    "    k = cv2.waitKey(0)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Gaussian Blur ( x2 +1 = in order to provide odd number for kernel size)\n",
    "    kernelSize = ((cv2.getTrackbarPos('gaussian blur','processed') * 2) + 1)\n",
    "    blur = cv2.GaussianBlur(img,(kernelSize,kernelSize),0)\n",
    "    # Threshold\n",
    "    ret,thresh = cv2.threshold(blur,cv2.getTrackbarPos('threshold','processed',),255,0)\n",
    "    # show result\n",
    "    cv2.imshow('gaussian blur',blur)\n",
    "    cv2.imshow('thresh ',thresh)\n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "# exit\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black and White  img = cv2.imread('image_sized.png',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 64\n",
      "threshold 75\n",
      "threshold 95\n",
      "threshold 111\n",
      "threshold 126\n",
      "threshold 140\n",
      "threshold 155\n",
      "threshold 166\n",
      "threshold 174\n",
      "threshold 184\n",
      "threshold 192\n",
      "threshold 200\n",
      "threshold 208\n",
      "threshold 217\n",
      "threshold 225\n",
      "threshold 232\n",
      "threshold 240\n",
      "threshold 247\n",
      "threshold 250\n",
      "threshold 254\n",
      "threshold 255\n",
      "threshold 254\n",
      "threshold 248\n",
      "threshold 241\n",
      "threshold 232\n",
      "threshold 221\n",
      "threshold 211\n",
      "threshold 202\n",
      "threshold 191\n",
      "threshold 181\n",
      "threshold 170\n",
      "threshold 159\n",
      "threshold 147\n",
      "threshold 137\n",
      "threshold 123\n",
      "threshold 111\n",
      "threshold 97\n",
      "threshold 89\n",
      "threshold 85\n",
      "threshold 82\n",
      "gaussian blur kernel size 4\n",
      "gaussian blur kernel size 5\n",
      "gaussian blur kernel size 6\n",
      "gaussian blur kernel size 7\n",
      "gaussian blur kernel size 6\n",
      "gaussian blur kernel size 5\n",
      "gaussian blur kernel size 4\n",
      "gaussian blur kernel size 3\n",
      "gaussian blur kernel size 2\n",
      "gaussian blur kernel size 1\n",
      "gaussian blur kernel size 0\n",
      "gaussian blur kernel size 1\n",
      "gaussian blur kernel size 2\n",
      "gaussian blur kernel size 1\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/feedstock_root/build_artefacts/opencv_1495334243082/work/opencv-3.2.0/modules/imgproc/src/smooth.cpp:2098: error: (-215) ksize.width > 0 && ksize.width % 2 == 1 && ksize.height > 0 && ksize.height % 2 == 1 in function createGaussianKernels\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1db45b768605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Gaussian Blur ( x2 +1 = odd number for kernel size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mkernelSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTrackbarPos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gaussian blur'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'processed'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mblur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernelSize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernelSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblur\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTrackbarPos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'threshold'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'processed'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /feedstock_root/build_artefacts/opencv_1495334243082/work/opencv-3.2.0/modules/imgproc/src/smooth.cpp:2098: error: (-215) ksize.width > 0 && ksize.width % 2 == 1 && ksize.height > 0 && ksize.height % 2 == 1 in function createGaussianKernels\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# slider callbacks\n",
    "def printThreshold(x):\n",
    "    print \"threshold\",x\n",
    "def printGaussianBlur(x):\n",
    "    print \"gaussian blur kernel size\",x\n",
    "# make a window to add sliders/preview to\n",
    "cv2.namedWindow('processed')\n",
    "#make some sliders\n",
    "cv2.createTrackbar('threshold','processed',60,255,printThreshold)\n",
    "cv2.createTrackbar('gaussian blur','processed',3,10,printGaussianBlur)\n",
    "# load image\n",
    "img = cv2.imread('images/webcam-border.jpg',0)\n",
    "# continously process for quick feedback\n",
    "while 1:\n",
    "    # exit on ESC key\n",
    "    k = cv2.waitKey(0)\n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "\n",
    "    # Gaussian Blur ( x2 +1 = odd number for kernel size)\n",
    "    kernelSize = ((cv2.getTrackbarPos('gaussian blur','processed') * 2) + 1)\n",
    "    blur = cv2.GaussianBlur(img,(kernelSize,kernelSize),0)\n",
    "    # Threshold\n",
    "    ret,thresh = cv2.threshold(blur,cv2.getTrackbarPos('threshold','processed',),255,0)\n",
    "    # show result\n",
    "    cv2.imshow('processed ',thresh)\n",
    "\n",
    "# exit\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create a black image, a window\n",
    "#img = np.zeros((300,512,3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "cv2.namedWindow('hsv')\n",
    "cv2.namedWindow('masq')\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "img = cv2.imread('images/webcam-border.jpg', 1)\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('R-low','image',0,255,nothing)\n",
    "cv2.createTrackbar('R-high','image',0,255,nothing)\n",
    "\n",
    "cv2.createTrackbar('G-low','image',0,255,nothing)\n",
    "cv2.createTrackbar('G-high','image',0,255,nothing)\n",
    "\n",
    "cv2.createTrackbar('B-low','image',0,255,nothing)\n",
    "cv2.createTrackbar('B-high','image',0,255,nothing)\n",
    "\n",
    "\n",
    "while(1):\n",
    "    #ret, img = cap.read()\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "\n",
    "    # get current positions of four trackbars\n",
    "    rl = cv2.getTrackbarPos('Rlow','image')\n",
    "    rh = cv2.getTrackbarPos('Rhigh','image')\n",
    "\n",
    "    gl = cv2.getTrackbarPos('G-low','image')\n",
    "    gh = cv2.getTrackbarPos('G-high','image')\n",
    "\n",
    "    bl = cv2.getTrackbarPos('B-low','image')\n",
    "    bh = cv2.getTrackbarPos('B-high','image')\n",
    "\n",
    "    lower = np.array([rl,gl,bl])\n",
    "    upper = np.array([rh,gh,bh])\n",
    "\n",
    "    #print(rl)\n",
    "\n",
    "    img[:] = [bl,gl,rl]\n",
    "\n",
    "    # Threshold the HSV image to get only certain colors\n",
    "    mask = cv2.inRange(hsv, Rlow,Rhigh)    \n",
    "\n",
    "\n",
    "    res = cv2.bitwise_and(img, img, mask= mask)\n",
    "\n",
    "    cv2.imshow('image',img)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('hsv',hsv)\n",
    "    cv2.imshow('res',res)\n",
    "    \n",
    "     # exit on ESC key\n",
    "    k = cv2.waitKey(0)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep above here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Python Program to blur image\n",
    "import cv2 \n",
    "#This will give an error if you don't have cv2 module\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "img = cv2.imread('images/webcam2.jpg', 1) \n",
    "\n",
    "cv2.createTrackbar('low','image',5,25,nothing)\n",
    "cv2.createTrackbar('high','image',5,25,nothing)\n",
    "\n",
    "while(1):\n",
    "  \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    \n",
    "    # get current positions of four trackbars\n",
    "    k1 = cv2.getTrackbarPos('low','image')\n",
    "    k2 = cv2.getTrackbarPos('high','image')\n",
    "    \n",
    "    lower = np.array([k1])\n",
    "    upper = np.array([k2])\n",
    "    \n",
    "    #make sure that you have saved it in the same folder\n",
    "    #blurImg = cv2.blur(img,(k1, k2)) #You can change the kernel size as you want\n",
    "    #cv2.imshow('blurred image',blurImg)\n",
    "    cv2.imshow('image',img)\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "\n",
    "    # get current positions of four trackbars\n",
    "    k1 = cv2.getTrackbarPos('low','image')\n",
    "    k2 = cv2.getTrackbarPos('high','image')\n",
    "\n",
    "    #print(rl)\n",
    "\n",
    "   \n",
    "\n",
    "    # Threshold the HSV image to get only certain colors\n",
    "    mask = cv2.inRange(hsv, lower, upper)    \n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------ run above ------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create a black image, a window\n",
    "#img = np.zeros((300,512,3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "cv2.namedWindow('hsv')\n",
    "cv2.namedWindow('masq')\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "img = cv2.imread('images/webcam2.jpg', 1)\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('R-low','image',0,255,nothing)\n",
    "cv2.createTrackbar('R-high','image',0,255,nothing)\n",
    "\n",
    "cv2.createTrackbar('G-low','image',0,255,nothing)\n",
    "cv2.createTrackbar('G-high','image',0,255,nothing)\n",
    "\n",
    "cv2.createTrackbar('B-low','image',0,255,nothing)\n",
    "cv2.createTrackbar('B-high','image',0,255,nothing)\n",
    "\n",
    "\n",
    "while(1):\n",
    "    #ret, img = cap.read()\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    res = cv2.bitwise_and(img, img, mask= mask)\n",
    "    cv2.imshow('image',img)\n",
    "    cv2.imshow('res',res)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "\n",
    "    # get current positions of four trackbars\n",
    "    rl = cv2.getTrackbarPos('R-low','image')\n",
    "    rh = cv2.getTrackbarPos('R-high','image')\n",
    "\n",
    "    gl = cv2.getTrackbarPos('G-low','image')\n",
    "    gh = cv2.getTrackbarPos('G-high','image')\n",
    "\n",
    "    bl = cv2.getTrackbarPos('B-low','image')\n",
    "    bh = cv2.getTrackbarPos('B-high','image')\n",
    "\n",
    "    lower = np.array([rl,gl,bl])\n",
    "    upper = np.array([rh,gh,bh])\n",
    "\n",
    "    #print(rl)\n",
    "\n",
    "    img[:] = [bl,gl,rl]\n",
    "\n",
    "    # Threshold the HSV image to get only certain colors\n",
    "    mask = cv2.inRange(hsv, lower, upper)    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    cv2.imshow('image',img)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('hsv',hsv)\n",
    "    cv2.imshow('res',res)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_val  = [0 0 0, ..., 249 249 250],[math.floor(n_cols * half_percent)]\n",
    "print low_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ______ WORKS WELL _______\n",
    "# Get Colors from a Trackbar\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create a black image, a window\n",
    "img = np.zeros((300,300,3), np.uint8)\n",
    "#Name your window\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "# create trackbars for color change place them in namedWindow('image')\n",
    "cv2.createTrackbar('R','image',0,255,nothing)\n",
    "cv2.createTrackbar('G','image',0,255,nothing)\n",
    "cv2.createTrackbar('B','image',0,255,nothing)\n",
    "\n",
    "# create switch for ON/OFF functionality\n",
    "switch = '0 : OFF \\n1 : ON'\n",
    "cv2.createTrackbar(switch, 'image',0,1,nothing)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # get current positions of four trackbars\n",
    "    r = cv2.getTrackbarPos('R','image')\n",
    "    g = cv2.getTrackbarPos('G','image')\n",
    "    b = cv2.getTrackbarPos('B','image')\n",
    "    s = cv2.getTrackbarPos(switch,'image')\n",
    "\n",
    "    if s == 0:\n",
    "        img[:] = 0\n",
    "    else:\n",
    "        img[:] = [b,g,r]\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "def nothing(x):\n",
    "    pass\n",
    " \n",
    "img_noblur = cv2.imread('images/webcam2.jpg', 0)\n",
    "img = cv2.blur(img_noblur, (7,7))\n",
    "canny_edge = cv2.Canny(img, 0, 0)\n",
    "\n",
    "cv2.createTrackbar('min_value','canny_edge',0,500,nothing)\n",
    "cv2.createTrackbar('max_value','canny_edge',0,500,nothing)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "min_value = cv2.getTrackbarPos('min_value', 'canny_edge')\n",
    "max_value = cv2.getTrackbarPos('max_value', 'canny_edge')\n",
    "\n",
    "canny_edge = cv2.Canny(img, min_value, max_value)\n",
    "cv2.imshow('image', img)\n",
    "cv2.imshow('canny_edge', canny_edge)\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "# exit on ESC key\n",
    "k = cv2.waitKey(1)\n",
    "if k == 27:\n",
    "\n",
    "        \n",
    "      \n",
    "        \n",
    "     cv2.destroyAllWindows()        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I'm using Python OpenCV to implement an adaptive skin color filter that uses haarcascades to detect an upright face, followed by filtering the face ROI to remove non-skin features like eyebrows, glasses etc to get the average skin tone (in RGB). Then I convert the image to HSV and extract the HSV values close to the average I obtained. Here is my code:\n",
    "import cv2\n",
    "import numpy as np\n",
    "from functions import *\n",
    "def nothing(x):\n",
    "    pass\n",
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.imread(\"images/webcam2.jpg\")\n",
    "face_cascade = cv2.CascadeClassifier('/home/jack/Desktop/deep-dream-generator/notebooks/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "#cv2.namedWindow('Video')\n",
    "#cv2.moveWindow('Video',5,5)\n",
    "#cv2.namedWindow('HSV_Thresh')\n",
    "#cv2.moveWindow('HSV_Thresh',655,5)\n",
    "cv2.createTrackbar('tval', 'Video', 29, 255, nothing)\n",
    "cv2.createTrackbar('htoler', 'HSV_Thresh', 17, 100, nothing)\n",
    "cv2.createTrackbar('stoler', 'HSV_Thresh', 25, 100, nothing)\n",
    "cv2.createTrackbar('vtoler', 'HSV_Thresh', 84, 100, nothing)\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)# 5X5 erosion kernel\n",
    "bavg=0\n",
    "ravg=0\n",
    "gavg=0\n",
    "while True: \n",
    "    tval1=cv2.getTrackbarPos('tval', 'cap')#thresh value to remove non skin components from face\n",
    "    htoler_val=cv2.getTrackbarPos('htoler', 'HSV_Thresh')\n",
    "    stoler_val=cv2.getTrackbarPos('stoler', 'HSV_Thresh')\n",
    "    vtoler_val=cv2.getTrackbarPos('vtoler', 'HSV_Thresh')\n",
    "    #ret,img=cv2.imread(\"image_sized.png\")#Read from source\n",
    "    img=cv2.imread(\"images/webcam2.jpg\")#Read from source\n",
    "    img[0:100,0:100] = [255,255,255]\n",
    "    thresh_hsv_toler=img    \n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        bavg=0\n",
    "        ravg=0\n",
    "        gavg=0\n",
    "        numpix=0\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        roi_face = img[y:y+h, x:x+w]\n",
    "        #avg_col=img[100,100]\n",
    "        rect_face=img[y:y+h-h/8,x+w/7:x+w-w/5]#extract only skin features from remaining bg\n",
    "        mask=cv2.inRange(rect_face,(tval1,tval1,tval1),(255,255,255))\n",
    "        mask=cv2.cvtColor(mask,cv2.COLOR_GRAY2BGR)\n",
    "        tone=cv2.subtract(mask,rect_face)\n",
    "        tone=cv2.subtract(mask,tone)\n",
    "        (rows,cols,col)=tone.shape # 480 rows and 640 cols; 3 values for RGB img\n",
    "        for i in range(rows): #note the presence of colon\n",
    "            for j in range(cols):\n",
    "                if (tone[i,j,0]!=0 and tone[i,j,0]!=0 and tone[i,j,0]!=0):\n",
    "                    bavg=bavg+tone[i,j,0]\n",
    "                    gavg=gavg+tone[i,j,1]\n",
    "                    ravg=ravg+tone[i,j,2]\n",
    "                    numpix=numpix+1\n",
    "                    bavg=bavg/numpix\n",
    "                    gavg=gavg/numpix\n",
    "                    ravg=ravg/numpix\n",
    "                    '''print \"bavg=\"+str(bavg)\n",
    "                    print \"gavg=\"+str(gavg)\n",
    "                    print \"ravg=\"+str(ravg)\n",
    "                    print \"numpix=\"+str(numpix)'''\n",
    "                    cv2.circle(img, (50,50), 20, (bavg,gavg,ravg), 50)#get obtained average colour on screen\n",
    "\n",
    "\n",
    "                    cv2.imshow('skin_mask', tone)\n",
    "                    hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "                    thresh_hsv_toler=cv2.inRange(hsv,(hsv[50,50,0]-htoler_val,hsv[50,50,1]-stoler_val,hsv[50,50,2]-vtoler_val),(hsv[50,50,0]+htoler_val,hsv[50,50,1]+stoler_val,hsv[50,50,2]+vtoler_val))\n",
    "\n",
    "                    thresh_hsv_toler=cv2.dilate(thresh_hsv_toler, kernel, iterations=1)\n",
    "                    thresh_hsv_toler=cv2.cvtColor(thresh_hsv_toler,cv2.COLOR_GRAY2BGR)#superimposing binary mask on image\n",
    "                    hsv_filter=cv2.subtract(thresh_hsv_toler,img)\n",
    "                    hsv_filter=cv2.subtract(thresh_hsv_toler,hsv_filter)\n",
    "\n",
    "\n",
    "\n",
    "                    cv2.imshow('HSV_Thresh', hsv_filter)\n",
    "                    cv2.imshow('Video', img)\n",
    "                    if(cv2.waitKey(10) & 0xFF == ord('b')):\n",
    "                        break\n",
    "                    cv2.imshow('Video', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I'm using Python OpenCV to implement an adaptive skin color filter that uses haarcascades to detect an upright face, followed by filtering the face ROI to remove non-skin features like eyebrows, glasses etc to get the average skin tone (in RGB). Then I convert the image to HSV and extract the HSV values close to the average I obtained. Here is my code:\n",
    "import cv2\n",
    "import numpy as np\n",
    "from functions import *\n",
    "def nothing(x):\n",
    "    pass\n",
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.imread(\"images/webcam.border.jpg\")\n",
    "face_cascade = cv2.CascadeClassifier('/home/jack/Desktop/deep-dream-generator/notebooks/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "cv2.namedWindow('Video')\n",
    "cv2.moveWindow('Video',5,5)\n",
    "cv2.namedWindow('HSV_Thresh')\n",
    "cv2.moveWindow('HSV_Thresh',655,5)\n",
    "cv2.createTrackbar('tval', 'Video', 29, 255, nothing)\n",
    "cv2.createTrackbar('htoler', 'HSV_Thresh', 17, 100, nothing)\n",
    "cv2.createTrackbar('stoler', 'HSV_Thresh', 25, 100, nothing)\n",
    "cv2.createTrackbar('vtoler', 'HSV_Thresh', 84, 100, nothing)\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)# 5X5 erosion kernel\n",
    "bavg=0\n",
    "ravg=0\n",
    "gavg=0\n",
    "while True: \n",
    "    tval1=cv2.getTrackbarPos('tval', 'Video')#thresh value to remove non skin components from face\n",
    "    htoler_val=cv2.getTrackbarPos('htoler', 'HSV_Thresh')\n",
    "    stoler_val=cv2.getTrackbarPos('stoler', 'HSV_Thresh')\n",
    "    vtoler_val=cv2.getTrackbarPos('vtoler', 'HSV_Thresh')\n",
    "    #ret,img=cv2.imread(\"image_sized.png\")#Read from source\n",
    "    img=cv2.imread(\"image_sized.png\")#Read from source\n",
    "    img[0:100,0:100] = [255,255,255]\n",
    "    thresh_hsv_toler=img    \n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        bavg=0\n",
    "        ravg=0\n",
    "        gavg=0\n",
    "        numpix=0\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        roi_face = img[y:y+h, x:x+w]\n",
    "        #avg_col=img[100,100]\n",
    "        rect_face=img[y:y+h-h/8,x+w/7:x+w-w/5]#extract only skin features from remaining bg\n",
    "        mask=cv2.inRange(rect_face,(tval1,tval1,tval1),(255,255,255))\n",
    "        mask=cv2.cvtColor(mask,cv2.COLOR_GRAY2BGR)\n",
    "        tone=cv2.subtract(mask,rect_face)\n",
    "        tone=cv2.subtract(mask,tone)\n",
    "        (rows,cols,col)=tone.shape # 480 rows and 640 cols; 3 values for RGB img\n",
    "        for i in range(rows): #note the presence of colon\n",
    "            for j in range(cols):\n",
    "                if (tone[i,j,0]!=0 and tone[i,j,0]!=0 and tone[i,j,0]!=0):\n",
    "                    bavg=bavg+tone[i,j,0]\n",
    "                    gavg=gavg+tone[i,j,1]\n",
    "                    ravg=ravg+tone[i,j,2]\n",
    "                    numpix=numpix+1\n",
    "                    bavg=bavg/numpix\n",
    "                    gavg=gavg/numpix\n",
    "                    ravg=ravg/numpix\n",
    "                    '''print \"bavg=\"+str(bavg)\n",
    "                    print \"gavg=\"+str(gavg)\n",
    "                    print \"ravg=\"+str(ravg)\n",
    "                    print \"numpix=\"+str(numpix)'''\n",
    "                    cv2.circle(img, (50,50), 20, (bavg,gavg,ravg), 50)#get obtained average colour on screen\n",
    "\n",
    "\n",
    "                    cv2.imshow('skin_mask', tone)\n",
    "                    hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "                    thresh_hsv_toler=cv2.inRange(hsv,(hsv[50,50,0]-htoler_val,hsv[50,50,1]-stoler_val,hsv[50,50,2]-vtoler_val),(hsv[50,50,0]+htoler_val,hsv[50,50,1]+stoler_val,hsv[50,50,2]+vtoler_val))\n",
    "\n",
    "                    thresh_hsv_toler=cv2.dilate(thresh_hsv_toler, kernel, iterations=1)\n",
    "                    thresh_hsv_toler=cv2.cvtColor(thresh_hsv_toler,cv2.COLOR_GRAY2BGR)#superimposing binary mask on image\n",
    "                    hsv_filter=cv2.subtract(thresh_hsv_toler,img)\n",
    "                    hsv_filter=cv2.subtract(thresh_hsv_toler,hsv_filter)\n",
    "\n",
    "\n",
    "\n",
    "                    cv2.imshow('HSV_Thresh', hsv_filter)\n",
    "\n",
    "\n",
    "                    if(cv2.waitKey(10) & 0xFF == ord('b')):\n",
    "                        break\n",
    "                    cv2.imshow('Video', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I'm using Python OpenCV to implement an adaptive skin color filter that uses haarcascades to detect an upright face, followed by filtering the face ROI to remove non-skin features like eyebrows, glasses etc to get the average skin tone (in RGB). Then I convert the image to HSV and extract the HSV values close to the average I obtained. Here is my code:\n",
    "import cv2\n",
    "import numpy as np\n",
    "from functions import *\n",
    "def nothing(x):\n",
    "    pass\n",
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.imread(\"images/image_sized.png\")\n",
    "face_cascade = cv2.CascadeClassifier('/home/jack/Desktop/deep-dream-generator/notebooks/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "cv2.namedWindow('Video')\n",
    "cv2.moveWindow('Video',5,5)\n",
    "cv2.namedWindow('HSV_Thresh')\n",
    "cv2.moveWindow('HSV_Thresh',655,5)\n",
    "cv2.createTrackbar('tval', 'Video', 29, 255, nothing)\n",
    "cv2.createTrackbar('htoler', 'HSV_Thresh', 17, 100, nothing)\n",
    "cv2.createTrackbar('stoler', 'HSV_Thresh', 25, 100, nothing)\n",
    "cv2.createTrackbar('vtoler', 'HSV_Thresh', 84, 100, nothing)\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)# 5X5 erosion kernel\n",
    "bavg=0\n",
    "ravg=0\n",
    "gavg=0\n",
    "while True: \n",
    "    tval1=cv2.getTrackbarPos('tval', 'Video')#thresh value to remove non skin components from face\n",
    "    htoler_val=cv2.getTrackbarPos('htoler', 'HSV_Thresh')\n",
    "    stoler_val=cv2.getTrackbarPos('stoler', 'HSV_Thresh')\n",
    "    vtoler_val=cv2.getTrackbarPos('vtoler', 'HSV_Thresh')\n",
    "    #ret,img=cv2.imread(\"image_sized.png\")#Read from source\n",
    "    img=cv2.imread(\"images/image_sized.png\")#Read from source\n",
    "    img[0:100,0:100] = [255,255,255]\n",
    "    thresh_hsv_toler=img    \n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        bavg=0\n",
    "        ravg=0\n",
    "        gavg=0\n",
    "        numpix=0\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        roi_face = img[y:y+h, x:x+w]\n",
    "        #avg_col=img[100,100]\n",
    "        rect_face=img[y:y+h-h/8,x+w/7:x+w-w/5]#extract only skin features from remaining bg\n",
    "        mask=cv2.inRange(rect_face,(tval1,tval1,tval1),(255,255,255))\n",
    "        mask=cv2.cvtColor(mask,cv2.COLOR_GRAY2BGR)\n",
    "        tone=cv2.subtract(mask,rect_face)\n",
    "        tone=cv2.subtract(mask,tone)\n",
    "        (rows,cols,col)=tone.shape # 480 rows and 640 cols; 3 values for RGB img\n",
    "        for i in range(rows): #note the presence of colon\n",
    "            for j in range(cols):\n",
    "                if (tone[i,j,0]!=0 and tone[i,j,0]!=0 and tone[i,j,0]!=0):\n",
    "                bavg=bavg+tone[i,j,0]\n",
    "                gavg=gavg+tone[i,j,1]\n",
    "                ravg=ravg+tone[i,j,2]\n",
    "                numpix=numpix+1\n",
    "                bavg=bavg/numpix\n",
    "                gavg=gavg/numpix\n",
    "                ravg=ravg/numpix\n",
    "                '''print \"bavg=\"+str(bavg)\n",
    "                print \"gavg=\"+str(gavg)\n",
    "                print \"ravg=\"+str(ravg)\n",
    "                print \"numpix=\"+str(numpix)'''\n",
    "                cv2.circle(img, (50,50), 20, (bavg,gavg,ravg), 50)#get obtained average colour on screen\n",
    "\n",
    "\n",
    "                cv2.imshow('skin_mask', tone)\n",
    "                hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "                thresh_hsv_toler=cv2.inRange(hsv,(hsv[50,50,0]-htoler_val,hsv[50,50,1]-stoler_val,hsv[50,50,2]-vtoler_val),(hsv[50,50,0]+htoler_val,hsv[50,50,1]+stoler_val,hsv[50,50,2]+vtoler_val))\n",
    "\n",
    "                thresh_hsv_toler=cv2.dilate(thresh_hsv_toler, kernel, iterations=1)\n",
    "                thresh_hsv_toler=cv2.cvtColor(thresh_hsv_toler,cv2.COLOR_GRAY2BGR)#superimposing binary mask on image\n",
    "                hsv_filter=cv2.subtract(thresh_hsv_toler,img)\n",
    "                hsv_filter=cv2.subtract(thresh_hsv_toler,hsv_filter)\n",
    "\n",
    "\n",
    "\n",
    "                cv2.imshow('HSV_Thresh', hsv_filter)\n",
    "\n",
    "\n",
    "                if(cv2.waitKey(10) & 0xFF == ord('b')):\n",
    "                break\n",
    "                cv2.imshow('Video', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I'm using Python OpenCV to implement an adaptive skin color filter that uses haarcascades to detect an upright face, followed by filtering the face ROI to remove non-skin features like eyebrows, glasses etc to get the average skin tone (in RGB). Then I convert the image to HSV and extract the HSV values close to the average I obtained. Here is my code:\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from functions import *\n",
    "def nothing(x):\n",
    "    pass\n",
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.imread(\"images/image_sized.png\")\n",
    "face_cascade = cv2.CascadeClassifier('/home/jack/Desktop/deep-dream-generator/notebooks/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "cv2.namedWindow('Video')\n",
    "cv2.moveWindow('Video',5,5)\n",
    "cv2.namedWindow('HSV_Thresh')\n",
    "cv2.moveWindow('HSV_Thresh',655,5)\n",
    "cv2.createTrackbar('tval', 'Video', 29, 255, nothing)\n",
    "cv2.createTrackbar('htoler', 'HSV_Thresh', 17, 100, nothing)\n",
    "cv2.createTrackbar('stoler', 'HSV_Thresh', 25, 100, nothing)\n",
    "cv2.createTrackbar('vtoler', 'HSV_Thresh', 84, 100, nothing)\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)# 5X5 erosion kernel\n",
    "bavg=0\n",
    "ravg=0\n",
    "gavg=0\n",
    "while True: \n",
    "    tval1=cv2.getTrackbarPos('tval', 'Video')#thresh value to remove non skin components from face\n",
    "    htoler_val=cv2.getTrackbarPos('htoler', 'HSV_Thresh')\n",
    "    stoler_val=cv2.getTrackbarPos('stoler', 'HSV_Thresh')\n",
    "    vtoler_val=cv2.getTrackbarPos('vtoler', 'HSV_Thresh')\n",
    "    #ret,img=cv2.imread(\"image_sized.png\")#Read from source\n",
    "    img=cv2.imread(\"image_sized.png\")#Read from source\n",
    "    img[0:100,0:100] = [255,255,255]\n",
    "    thresh_hsv_toler=img    \n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        bavg=0\n",
    "        ravg=0\n",
    "        gavg=0\n",
    "        numpix=0\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        roi_face = img[y:y+h, x:x+w]\n",
    "        #avg_col=img[100,100]\n",
    "        rect_face=img[y:y+h-h/8,x+w/7:x+w-w/5]#extract only skin features from remaining bg\n",
    "        mask=cv2.inRange(rect_face,(tval1,tval1,tval1),(255,255,255))\n",
    "        mask=cv2.cvtColor(mask,cv2.COLOR_GRAY2BGR)\n",
    "        tone=cv2.subtract(mask,rect_face)\n",
    "        tone=cv2.subtract(mask,tone)\n",
    "        (rows,cols,col)=tone.shape # 480 rows and 640 cols; 3 values for RGB img\n",
    "    for i in range(rows): #note the presence of colon\n",
    "        for j in range(cols):\n",
    "            if (tone[i,j,0]!=0 and tone[i,j,0]!=0 and tone[i,j,0]!=0):\n",
    "            bavg=bavg+tone[i,j,0]\n",
    "            gavg=gavg+tone[i,j,1]\n",
    "            ravg=ravg+tone[i,j,2]\n",
    "            numpix=numpix+1\n",
    "            bavg=bavg/numpix\n",
    "            gavg=gavg/numpix\n",
    "            ravg=ravg/numpix\n",
    "            '''print \"bavg=\"+str(bavg)\n",
    "            print \"gavg=\"+str(gavg)\n",
    "            print \"ravg=\"+str(ravg)\n",
    "            print \"numpix=\"+str(numpix)'''\n",
    "            cv2.circle(img, (50,50), 20, (bavg,gavg,ravg), 50)#get obtained average colour on screen\n",
    "\n",
    "\n",
    "            cv2.imshow('skin_mask', tone)\n",
    "            hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "            thresh_hsv_toler=cv2.inRange(hsv,(hsv[50,50,0]-htoler_val,hsv[50,50,1]-stoler_val,hsv[50,50,2]-vtoler_val),(hsv[50,50,0]+htoler_val,hsv[50,50,1]+stoler_val,hsv[50,50,2]+vtoler_val))\n",
    "\n",
    "            thresh_hsv_toler=cv2.dilate(thresh_hsv_toler, kernel, iterations=1)\n",
    "            thresh_hsv_toler=cv2.cvtColor(thresh_hsv_toler,cv2.COLOR_GRAY2BGR)#superimposing binary mask on image\n",
    "            hsv_filter=cv2.subtract(thresh_hsv_toler,img)\n",
    "            hsv_filter=cv2.subtract(thresh_hsv_toler,hsv_filter)\n",
    "\n",
    "\n",
    "\n",
    "            cv2.imshow('HSV_Thresh', hsv_filter)\n",
    "\n",
    "\n",
    "        if(cv2.waitKey(10) & 0xFF == ord('b')):\n",
    "break\n",
    "    cv2.imshow('Video', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "'''\n",
    "Coherence-enhancing filtering example\n",
    "=====================================\n",
    "inspired by\n",
    "  Joachim Weickert \"Coherence-Enhancing Shock Filters\"\n",
    "  http://www.mia.uni-saarland.de/Publications/weickert-dagm03.pdf\n",
    "'''\n",
    "\n",
    "# Python 2/3 compatibility\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "PY3 = sys.version_info[0] == 3\n",
    "\n",
    "if PY3:\n",
    "    xrange = range\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def coherence_filter(img, sigma = 11, str_sigma = 11, blend = 0.5, iter_n = 4):\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    for i in xrange(iter_n):\n",
    "        print(i)\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        eigen = cv2.cornerEigenValsAndVecs(gray, str_sigma, 3)\n",
    "        eigen = eigen.reshape(h, w, 3, 2)  # [[e1, e2], v1, v2]\n",
    "        x, y = eigen[:,:,1,0], eigen[:,:,1,1]\n",
    "\n",
    "        gxx = cv2.Sobel(gray, cv2.CV_32F, 2, 0, ksize=sigma)\n",
    "        gxy = cv2.Sobel(gray, cv2.CV_32F, 1, 1, ksize=sigma)\n",
    "        gyy = cv2.Sobel(gray, cv2.CV_32F, 0, 2, ksize=sigma)\n",
    "        gvv = x*x*gxx + 2*x*y*gxy + y*y*gyy\n",
    "        m = gvv < 0\n",
    "\n",
    "        ero = cv2.erode(img, None)\n",
    "        dil = cv2.dilate(img, None)\n",
    "        img1 = ero\n",
    "        img1[m] = dil[m]\n",
    "        img = np.uint8(img*(1.0 - blend) + img1*blend)\n",
    "    print('done')\n",
    "    return img\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import sys\n",
    "    try:\n",
    "        fn = sys.argv[1]\n",
    "    except:\n",
    "        fn = 'images/image_sized.png'\n",
    "\n",
    "    src = cv2.imread(fn)\n",
    "\n",
    "    def nothing(*argv):\n",
    "        pass\n",
    "\n",
    "    def update():\n",
    "        sigma = cv2.getTrackbarPos('sigma', 'control')*2+1\n",
    "        str_sigma = cv2.getTrackbarPos('str_sigma', 'control')*2+1\n",
    "        blend = cv2.getTrackbarPos('blend', 'control') / 10.0\n",
    "        print('sigma: %d  str_sigma: %d  blend_coef: %f' % (sigma, str_sigma, blend))\n",
    "        dst = coherence_filter(src, sigma=sigma, str_sigma = str_sigma, blend = blend)\n",
    "        cv2.imshow('dst', dst)\n",
    "\n",
    "    cv2.namedWindow('control', 0)\n",
    "    cv2.createTrackbar('sigma', 'control', 9, 15, nothing)\n",
    "    cv2.createTrackbar('blend', 'control', 7, 10, nothing)\n",
    "    cv2.createTrackbar('str_sigma', 'control', 9, 15, nothing)\n",
    "\n",
    "\n",
    "    print('Press SPACE to update the image\\n')\n",
    "\n",
    "    cv2.imshow('src', src)\n",
    "    update()\n",
    "    while True:\n",
    "        ch = cv2.waitKey()\n",
    "        if ch == ord(' '):\n",
    "            update()\n",
    "        if ch == 27:\n",
    "            break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2;\n",
    "import numpy as np;\n",
    " \n",
    "# Read image\n",
    "im_in = cv2.imread(\"images/webcam-border.png\", cv2.IMREAD_GRAYSCALE);\n",
    " \n",
    "# Threshold.\n",
    "# Set values equal to or above 220 to 0.\n",
    "# Set values below 220 to 255.\n",
    " \n",
    "th, im_th = cv2.threshold(im_in, 120, 255, cv2.THRESH_BINARY_INV);\n",
    " \n",
    "# Copy the thresholded image.\n",
    "im_floodfill = im_th.copy()\n",
    " \n",
    "# Mask used to flood filling.\n",
    "# Notice the size needs to be 2 pixels than the image.\n",
    "h, w = im_th.shape[:2]\n",
    "mask = np.zeros((h+2, w+2), np.uint8)\n",
    " \n",
    "# Floodfill from point (0, 0)\n",
    "cv2.floodFill(im_floodfill, mask, (0,0), 255);\n",
    " \n",
    "# Invert floodfilled image\n",
    "im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
    " \n",
    "# Combine the two images to get the foreground.\n",
    "im_out = im_th | im_floodfill_inv\n",
    " \n",
    "# Display images.\n",
    "cv2.imshow(\"Thresholded Image\", im_th)\n",
    "cv2.imshow(\"Floodfilled Image\", im_floodfill)\n",
    "cv2.imshow(\"Inverted Floodfilled Image\", im_floodfill_inv)\n",
    "cv2.imshow(\"Foreground\", im_out)\n",
    "while True:\n",
    "    ch = 0xFF & cv2.waitKey()\n",
    "    if ch == 27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update(dummy=35,65,img = cv2.imread(\"images/webcam-border.png\"))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "label = cv2.imread(\"images/webcam-border.png\")\n",
    "ormap = np.bitwise_or(label,detmap).astype(uint8)\n",
    "mask = np.zeros((image_size+2,imagesize+2),np.uint8)\n",
    "for y in range(image_size):\n",
    "    for x in range(image_size):\n",
    "        if label[y,x]>0:\n",
    "            cv2.floodFill(ormap,mask,(y,x),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"images/webcam-border.png\")\n",
    "h, w = image.shape[:2]\n",
    "mask = np.zeros((h+2, w+2), np.uint8)\n",
    "mask[:] |= 0\n",
    "flags = 4\n",
    "flags |= cv2.FLOODFILL_FIXED_RANGE\n",
    "           \n",
    "for x in range(20,image.shape[1]-20, 20):\n",
    "    for y in range(20,image.shape[0]-20, 20):\n",
    "        print x, y\n",
    "        mask[:] = 0\n",
    "        flooded = image.copy()\n",
    "        print 'starting flood fill'\n",
    "        size = cv2.floodFill(flooded,mask,(x,y),(0,)*3, (40,)*3, (40,)*3, flags)[0]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"images/webcam-border.png\")\n",
    "for x in range(20,image.shape[1]-20, 20):\n",
    "    for y in range(20,image.shape[0]-20, 20):\n",
    "        print x, y\n",
    "        mask[:] = 0\n",
    "        flooded = image.copy()\n",
    "        print 'starting flood fill'\n",
    "        size = cv2.floodFill(flooded,mask,(x,y),(0,)*3, (40,)*3, (40,)*3, flags)[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a short demo showing \n",
    "# some of the python filters. \n",
    "# I am using a Jupyter Notebook\n",
    "# to create and show the results \n",
    "# of the Python Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python program for Detection of a \n",
    "# specific color(blue here) using OpenCV with Python\n",
    "import cv2\n",
    "import numpy as np \n",
    " \n",
    "# Webcamera no 0 is used to capture the frames\n",
    "cap = cv2.VideoCapture(0) \n",
    " \n",
    "# This drives the program into an infinite loop.\n",
    "while(1):       \n",
    "    # Captures the live stream frame-by-frame\n",
    "    _, frame = cap.read() \n",
    "    # Converts images from BGR to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    lower_red = np.array([110,50,50])\n",
    "    upper_red = np.array([130,255,255])\n",
    " \n",
    "# Here we are defining range of bluecolor in HSV\n",
    "# This creates a mask of blue coloured \n",
    "# objects found in the frame.\n",
    "mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    " \n",
    "# The bitwise and of the frame and mask is done so \n",
    "# that only the blue coloured objects are highlighted \n",
    "# and stored in res\n",
    "res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "cv2.imshow('frame',frame)\n",
    "cv2.imshow('mask',mask)\n",
    "cv2.imshow('res',res)\n",
    " \n",
    "# This displays the frame, mask \n",
    "# and res which we created in 3 separate windows.\n",
    "k = cv2.waitKey(5) &amp; 0xFF\n",
    "if k == 27:\n",
    "break\n",
    " \n",
    "# Destroys all of the HighGUI windows.\n",
    "cv2.destroyAllWindows()\n",
    " \n",
    "# release the captured frame\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python program for Detection of a \n",
    "# specific color(blue here) using OpenCV with Python\n",
    "import cv2\n",
    "import numpy as np \n",
    " \n",
    "# Webcamera no 0 is used to capture the frames\n",
    "cap = cv2.VideoCapture(0) \n",
    " \n",
    "# This drives the program into an infinite loop.\n",
    "while(1):       \n",
    "    # Captures the live stream frame-by-frame\n",
    "    _, frame = cap.read() \n",
    "    # Converts images from BGR to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    #lower_red = np.array([110,50,50])\n",
    "    #upper_red = np.array([130,255,255])\n",
    "    cv2.createTrackbar('lowH','image',ilowH,180,callback)\n",
    "    cv2.createTrackbar('highH','image',ihighH,255,callback)\n",
    "    lH = cv2.getTrackbarPos('lowH','image')\n",
    "    hH = cv2.getTrackbarPos('highH','image')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    lower_red = np.array([lH,0,0])\n",
    "    upper_red = np.array([hH,255,255])\n",
    " \n",
    "    # Here we are defining range of bluecolor in HSV\n",
    "    # This creates a mask of blue coloured \n",
    "    # objects found in the frame.\n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    mask = mask - 255\n",
    "    # The bitwise and of the frame and mask is done so \n",
    "    # that only the blue coloured objects are highlighted \n",
    "    # and stored in res\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "\n",
    "    # This displays the frame, mask \n",
    "    # and res which we created in 3 separate windows.\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python program for Detection of a \n",
    "# specific color(blue here) using OpenCV with Python\n",
    "import cv2\n",
    "import numpy as np \n",
    " \n",
    "# Webcamera no 0 is used to capture the frames\n",
    "cap = cv2.VideoCapture(0) \n",
    "cv2.namedWindow('image') \n",
    "# This drives the program into an infinite loop.\n",
    "ilowH = 180\n",
    "IhighH = 255\n",
    "\n",
    "while(1):       \n",
    "    # Captures the live stream frame-by-frame\n",
    "    _, frame = cap.read() \n",
    "    # Converts images from BGR to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    #lower_red = np.array([110,50,50])\n",
    "    #upper_red = np.array([130,255,255])\n",
    "    \n",
    "    \n",
    "    cv2.createTrackbar('lowH','image',ilowH,180,callback)\n",
    "    cv2.createTrackbar('highH','image',ihighH,255,callback)\n",
    "    lH = cv2.getTrackbarPos('lowH','image')\n",
    "    hH = cv2.getTrackbarPos('highH','image')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    lower_red = np.array([lH,0,0])\n",
    "    upper_red = np.array([hH,255,255])\n",
    " \n",
    "    # Here we are defining range of bluecolor in HSV\n",
    "    # This creates a mask of blue coloured \n",
    "    # objects found in the frame.\n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    mask = mask - 255\n",
    "    # The bitwise and of the frame and mask is done so \n",
    "    # that only the blue coloured objects are highlighted \n",
    "    # and stored in res\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "\n",
    "    # This displays the frame, mask \n",
    "    # and res which we created in 3 separate windows.\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#WORKING FINE\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def callback(x):\n",
    "    pass\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "ilowH = 180\n",
    "ihighH = 255\n",
    "\n",
    "ilowS = 0\n",
    "ihighS = 255\n",
    "\n",
    "ilowV = 0\n",
    "ihighV = 255\n",
    "\n",
    "thresl =0\n",
    "thresh =255\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('lowH','image',ilowH,180,callback)\n",
    "cv2.createTrackbar('highH','image',ihighH,255,callback)\n",
    "\n",
    "cv2.createTrackbar('lowS','image',ilowS,255,callback)\n",
    "cv2.createTrackbar('highS','image',ihighS,255,callback)\n",
    "\n",
    "cv2.createTrackbar('lowV','image',ilowV,255,callback)\n",
    "cv2.createTrackbar('highV','image',ihighV,255,callback)\n",
    "\n",
    "cv2.createTrackbar('lowT','image',thresl,127,callback)\n",
    "cv2.createTrackbar('highT','image',thresh,255,callback)\n",
    "\n",
    "\n",
    "while(1):\n",
    "    # get current positions of four trackbars\n",
    "    lH = cv2.getTrackbarPos('lowH','image')\n",
    "    hH = cv2.getTrackbarPos('highH','image')\n",
    "    lS = cv2.getTrackbarPos('lowS','image')\n",
    "    hS = cv2.getTrackbarPos('highS','image')\n",
    "    lV = cv2.getTrackbarPos('lowV','image')\n",
    "    hV = cv2.getTrackbarPos('highV','image')\n",
    "    lT = cv2.getTrackbarPos('lowT','image')\n",
    "    hT = cv2.getTrackbarPos('highT','image')\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    cv2.imshow('hsv', hsv)\n",
    "    lower_hsv = np.array([lH, lS, lV])\n",
    "    higher_hsv = np.array([hH, hS, hV])\n",
    "    mask = cv2.inRange(hsv, lower_hsv, higher_hsv)\n",
    "    mask = 255 - mask\n",
    "    result = cv2.bitwise_or(frame,frame, mask= mask)\n",
    "    hsvmask = cv2.bitwise_or(hsv,hsv, mask= mask)\n",
    "    \n",
    "    ret,thresh2 = cv2.threshold(frame,lT,hT,cv2.THRESH_BINARY) \n",
    "    \n",
    "    \n",
    "    #result = cv2.bitwise_not(frame,frame, mask= mask)\n",
    "    #hsvmask = cv2.bitwise_not(hsv,hsv, mask= mask)\n",
    "    cv2.imshow('thresh2', thresh2)\n",
    "    cv2.imshow('result', result)\n",
    "    cv2.imshow('mask', mask)\n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('hsvmask', hsvmask)\n",
    "    #print ilowH, ilowS, ilowV\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KEEP to WORK WITH\n",
    "import cv2\n",
    "import numpy as np\n",
    "# Read image\n",
    "im_in = cv2.imread('images/webcam-border.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "th, im_th = cv2.threshold(im_in, 50, 65, cv2.THRESH_BINARY_INV)\n",
    "# Copy the thresholded image.\n",
    "im_floodfill = im_th.copy()\n",
    "# Mask used to flood filling.\n",
    "h, w = im_th.shape[:2]\n",
    "mask = np.zeros((h+2, w+2), np.uint8)\n",
    "# Floodfill from point (0, 0)\n",
    "cv2.floodFill(im_floodfill, mask, (0,0), 255)\n",
    "# Invert floodfilled image\n",
    "im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
    "# Combine the two images to get the foreground.\n",
    "im_out = im_th | im_floodfill_inv\n",
    "# Display images.\n",
    "cv2.imshow(\"Foreground\", im_out)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# research weighted values\n",
    "# http://opencvpython.blogspot.com/2012/07/background-extraction-using-running.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a ghost \n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "c = cv2.VideoCapture(0)\n",
    "_,f = c.read()\n",
    " \n",
    "avg1 = np.float32(f)\n",
    "avg2 = np.float32(f)\n",
    " \n",
    "while(1):\n",
    "    _,f = c.read()\n",
    "     \n",
    "    cv2.accumulateWeighted(f,avg1,0.1)\n",
    "    cv2.accumulateWeighted(f,avg2,0.01)\n",
    "     \n",
    "    res1 = cv2.convertScaleAbs(avg1)\n",
    "    res2 = cv2.convertScaleAbs(avg2)\n",
    " \n",
    "    cv2.imshow('img',f)\n",
    "    cv2.imshow('avg1',res1)\n",
    "    cv2.imshow('avg2',res2)\n",
    "    k = cv2.waitKey(20)\n",
    " \n",
    "    if k == 27:\n",
    "        break\n",
    " \n",
    "cv2.destroyAllWindows()\n",
    "c.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/jack/Desktop/pycode/vpython2/webcam/samples\")\n",
    "import video\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "def Circles():\n",
    "    cv2.namedWindow('Circles')\n",
    "    cv2.namedWindow('parameters')\n",
    "\n",
    "    cv2.createTrackbar('dp', 'parameters', 1, 20, nothing)\n",
    "    cv2.createTrackbar('minDist', 'parameters', 10, 700, nothing)\n",
    "    cv2.createTrackbar('CannyParam', 'parameters', 1, 300, nothing)\n",
    "    cv2.createTrackbar('AccumulatorThrs', 'parameters', 1, 100, nothing)\n",
    "    cv2.createTrackbar('minRadius', 'parameters', 1, 50, nothing)\n",
    "    cv2.createTrackbar('maxRadius', 'parameters', 51, 700, nothing)\n",
    "\n",
    "\n",
    "    image = cv2.imread('images/webcam-border.png')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    gray = gray[:,:,2]\n",
    "    #cv2.imshow('ImageGray', gray)\n",
    "    while True:\n",
    "        dp = cv2.getTrackbarPos('dp', 'parameters')\n",
    "        minDist = cv2.getTrackbarPos('minDist', 'parameters')\n",
    "        CannyParam = cv2.getTrackbarPos('CannyParam', 'parameters')\n",
    "        AccumulatorThrs = cv2.getTrackbarPos('AccumulatorThrs', 'parameters')\n",
    "        minRadius = cv2.getTrackbarPos('minRadius', 'parameters')\n",
    "        maxRadius = cv2.getTrackbarPos('maxRadius', 'parameters')\n",
    "\n",
    "        circles = cv2.HoughCircles(gray,cv2.HOUGH_GRADIENT,dp,minDist,CannyParam,AccumulatorThrs,minRadius,maxRadius)\n",
    "        circles = np.uint16(np.around(circles))\n",
    "\n",
    "        for i in circles[0,:]:\n",
    "            cv2.circle(image,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "            cv2.circle(image,(i[0],i[1]),2,(0,0,255),3)\n",
    "\n",
    "            cv2.imshow('Circles', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "Circles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-ecb1ecad10ed>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-ecb1ecad10ed>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    def Foo(int,void*);\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "def Foo(int,void*);\n",
    "    \n",
    "# Create a black image, a window\n",
    "img = cv2.imread(\"images/webcam-border.png\")\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('R','image',0,255,nothing)\n",
    "cv2.createTrackbar('G','image',0,255,nothing)\n",
    "cv2.createTrackbar('B','image',0,255,nothing)\n",
    "cv2.createTrackbar('A','image',0,1000,Foo)\n",
    "\n",
    "#cv2.CreateTrackbar(trackbarName, windowName, value, count, onChange)\n",
    "\n",
    "# create switch for ON/OFF functionality\n",
    "switch = '0 : OFF \\n1 : ON'\n",
    "cv2.createTrackbar(switch, 'image',0,1,nothing)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # get current positions of four trackbars\n",
    "    r = cv2.getTrackbarPos('R','image')\n",
    "    g = cv2.getTrackbarPos('G','image')\n",
    "    b = cv2.getTrackbarPos('B','image')\n",
    "    a = cv2.getTrackbarPos('A','image')\n",
    "    s = cv2.getTrackbarPos(switch,'image')\n",
    "\n",
    "    if s == 0:\n",
    "        img[:] = 0\n",
    "    else:\n",
    "        img[:] = [b,g,r]\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    " \n",
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "img = cv2.imread(\"images/webcam-border.png\", True)\n",
    "\n",
    "\n",
    "if img is None:\n",
    "     print('Failed to load image file:', fn)\n",
    "     sys.exit(1)\n",
    " \n",
    "     h, w = img.shape[:2]\n",
    "     mask = np.zeros((h+2, w+2), np.uint8)\n",
    "     seed_pt = None\n",
    "     fixed_range = True\n",
    "     connectivity = 4\n",
    " \n",
    "     def update(dummy=None):\n",
    "         if seed_pt is None:\n",
    "             #cv2.imshow('floodfill', img)\n",
    "             cv2.namedWindow('floodfill') \n",
    "             return\n",
    "         flooded = img.copy()\n",
    "         mask[:] = 0\n",
    "         lo = cv2.getTrackbarPos('lo', 'floodfill')\n",
    "         hi = cv2.getTrackbarPos('hi', 'floodfill')\n",
    "         flags = connectivity\n",
    "         if fixed_range:\n",
    "             flags |= cv2.FLOODFILL_FIXED_RANGE\n",
    "         cv2.floodFill(flooded, mask, seed_pt, (255, 255, 255), (lo,)*3, (hi,)*3, flags)\n",
    "         cv2.circle(flooded, seed_pt, 2, (0, 0, 255), -1)\n",
    "         cv2.imshow('floodfill', flooded)\n",
    " \n",
    "     def onmouse(event, x, y, flags, param):\n",
    "         global seed_pt\n",
    "         if flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "             seed_pt = x, y\n",
    "             update()\n",
    " \n",
    "             update()\n",
    "             cv2.setMouseCallback('floodfill', onmouse)\n",
    "             cv2.createTrackbar('lo', 'floodfill', 20, 255, update)\n",
    "             cv2.createTrackbar('hi', 'floodfill', 20, 255, update)\n",
    "\n",
    "             while True:\n",
    "                 ch = cv2.waitKey()\n",
    "                 if ch == 27:\n",
    "                     break\n",
    "                 if ch == ord('f'):\n",
    "                     fixed_range = not fixed_range\n",
    "                     print('using %s range' % ('floating', 'fixed')[fixed_range])\n",
    "                     update()\n",
    "                 if ch == ord('c'):\n",
    "                     connectivity = 12-connectivity\n",
    "                     print('connectivity =', connectivity)\n",
    "                     update()\n",
    "             cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Below this line works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "#write simple update function to pass the trackbar position as *arg    \n",
    "def update(*arg): \n",
    "    pass\n",
    "\n",
    "#create display window for image\n",
    "cv2.namedWindow('BinaryThreshold') \n",
    "\n",
    "#read in image\n",
    "img = cv2.imread(r'images/webcam-border.png',0)\n",
    "\n",
    "#instantiate trackbar that goes in our named window and uses callback function\n",
    "cv2.createTrackbar('ThreshAdjust','BinaryThreshold',5,15,update)\n",
    "\n",
    "#initialize thresholds\n",
    "thresh1=11\n",
    "thresh2=5\n",
    "\n",
    "#loop really just runs until the escape key causes a break\n",
    "while(True):\n",
    "\n",
    "    #sets threshold 2 to trackbar position\n",
    "    thresh2=cv2.getTrackbarPos('ThreshAdjust','BinaryThreshold')   \n",
    "    #apply laplacian filter to ehance edge gradients\n",
    "    th = cv2.Laplacian(img,cv2.CV_8UC1)\n",
    "    #binarize image with adaptive threshold\n",
    "    result = cv2.adaptiveThreshold(th,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,thresh1,thresh2) \n",
    "\n",
    "    #show filtered image\n",
    "    cv2.imshow('BinaryThreshold',result)\n",
    "    #waits for escape key then breaks out of loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "\n",
    "#close our display window     \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ______ WORKS WELL _______\n",
    "# Get Colors from a Trackbar\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create a black image, a window\n",
    "img = np.zeros((300,300,3), np.uint8)\n",
    "#Name your window\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "# create trackbars for color change place them in namedWindow('image')\n",
    "cv2.createTrackbar('R','image',0,255,nothing)\n",
    "cv2.createTrackbar('G','image',0,255,nothing)\n",
    "cv2.createTrackbar('B','image',0,255,nothing)\n",
    "\n",
    "# create switch for ON/OFF functionality\n",
    "switch = '0 : OFF \\n1 : ON'\n",
    "cv2.createTrackbar(switch, 'image',0,1,nothing)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # get current positions of four trackbars\n",
    "    r = cv2.getTrackbarPos('R','image')\n",
    "    g = cv2.getTrackbarPos('G','image')\n",
    "    b = cv2.getTrackbarPos('B','image')\n",
    "    s = cv2.getTrackbarPos(switch,'image')\n",
    "\n",
    "    if s == 0:\n",
    "        img[:] = 0\n",
    "    else:\n",
    "        img[:] = [b,g,r]\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#/usr/bin/env python\n",
    "#Works Run from Jupyter Note book\n",
    "\n",
    "'''\n",
    "Floodfill sample.\n",
    "\n",
    "Usage:\n",
    "floodfill.py [<image>]\n",
    "\n",
    "Click on the image to set seed point\n",
    "\n",
    "Keys:\n",
    "f     - toggle floating range\n",
    "c     - toggle 4/8 connectivity\n",
    "ESC   - exit\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "import math\n",
    "import svgfig\n",
    "\n",
    "\n",
    "img = cv2.imread(\"images/webcam-border.png\", True)\n",
    "#img = cv2.imread(fn, True)\n",
    "h, w = img.shape[:2]\n",
    "mask = np.zeros((h+2, w+2), np.uint8)\n",
    "seed_pt = None\n",
    "fixed_range = True\n",
    "connectivity = 4\n",
    "history = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "def update_floodfill(dummy=None):\n",
    "    global history\n",
    "    if seed_pt is None:\n",
    "        cv2.imshow('floodfill', img)\n",
    "        return\n",
    "    flooded = img.copy()\n",
    "    mask[:] = 0\n",
    "    lo = cv2.getTrackbarPos('lo', 'floodfill')\n",
    "    hi = cv2.getTrackbarPos('hi', 'floodfill')\n",
    "    flags = (8 | 255 << 8) | cv2.FLOODFILL_MASK_ONLY\n",
    "    cv2.floodFill(flooded, mask, seed_pt, (255, 0, 0), (lo,)*3, (hi,)*3,\n",
    "                  flags)\n",
    "\n",
    "    # find outmost contour and fill it to remove everything inside\n",
    "    _,contours,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL,\n",
    "                                cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(mask, contours[0], 0, 255, cv2.FILLED)\n",
    "\n",
    "    # find edges\n",
    "    edges = cv2.Canny(mask, 80, 120)\n",
    "\n",
    "    # show blue lines on floodfill to show guessed lines\n",
    "    lines = cv2.HoughLinesP(edges, 1, math.pi/180, 1, 20, 2)\n",
    "    for line in lines[0]:\n",
    "        cv2.line(flooded, (line[0], line[1]), (line[2], line[3]), (255, 0, 0), 1)\n",
    "    cv2.circle(flooded, seed_pt, 2, (0, 0, 255), -1)\n",
    "\n",
    "    history = np.bitwise_or(history, edges)\n",
    "\n",
    "    # inverse it so that it's black edges on white\n",
    "    edges = cv2.bitwise_not(edges)\n",
    "\n",
    "    cv2.imshow('history', cv2.bitwise_not(history))\n",
    "    cv2.imshow('floodfill', flooded)\n",
    "\n",
    "def update_canny(dummy=None):\n",
    "    contour_map = np.zeros((h+2, w+2), np.uint8)\n",
    "    blue, green, red = cv2.split(img)\n",
    "\n",
    "    # Run canny edge detection on each channel\n",
    "    stroke = cv2.getTrackbarPos('stroke', 'canny')\n",
    "    lo = cv2.getTrackbarPos('lo', 'canny')\n",
    "    hi = cv2.getTrackbarPos('hi', 'canny')\n",
    "    min_size = cv2.getTrackbarPos('min_size', 'canny')\n",
    "    max_size = cv2.getTrackbarPos('max_size', 'canny')\n",
    "    blue_edges = cv2.Canny(img, lo, hi)\n",
    "    green_edges = cv2.Canny(img, lo, hi)\n",
    "    red_edges = cv2.Canny(img, lo, hi)\n",
    "    rgb_edges = blue_edges | green_edges | red_edges\n",
    "    cv2.imshow('edges', cv2.bitwise_not(rgb_edges))\n",
    "\n",
    "    _,contours, hierarchies = cv2.findContours(rgb_edges, cv2.RETR_TREE,\n",
    "                                           cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    filtered = []\n",
    "    for cnt, hierarchy in zip(contours, hierarchies[0]):\n",
    "        if hierarchy[3] < 0:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area >= min_size and area <= max_size:\n",
    "                filtered.append(cnt)\n",
    "\n",
    "    cv2.drawContours(contour_map, filtered, -1, 255, stroke)  # cv2.cv.CV_FILLED\n",
    "\n",
    "    lined = img.copy()\n",
    "    lines = cv2.HoughLinesP(contour_map, 1, math.pi/180, 1, 20, 2)\n",
    "    for line in lines[0]:\n",
    "        cv2.line(lined, (line[0], line[1]), (line[2], line[3]), (255, 0, 0), 1)\n",
    "\n",
    "    cv2.imshow('lined', lined)\n",
    "    cv2.imshow('contours', cv2.bitwise_not(contour_map))\n",
    "\n",
    "def onmouse(event, x, y, flags, param):\n",
    "    global seed_pt\n",
    "    if flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "        seed_pt = x, y\n",
    "        update_floodfill()\n",
    "\n",
    "update_floodfill()\n",
    "cv2.setMouseCallback('floodfill', onmouse)\n",
    "cv2.createTrackbar('lo', 'floodfill', 10, 255, update_floodfill)\n",
    "cv2.createTrackbar('hi', 'floodfill', 10, 255, update_floodfill)\n",
    "\n",
    "cv2.imshow('canny', img)\n",
    "# cv2.setMouseCallback('canny', update_canny)\n",
    "cv2.createTrackbar('min_size', 'canny', 200, 4000, update_canny)\n",
    "cv2.createTrackbar('max_size', 'canny', 4000, 60000, update_canny)\n",
    "cv2.createTrackbar('lo', 'canny', 60, 255, update_canny)\n",
    "cv2.createTrackbar('hi', 'canny', 180, 255, update_canny)\n",
    "cv2.createTrackbar('stroke', 'canny', 2, 6, update_canny)\n",
    "update_canny()\n",
    "\n",
    "while True:\n",
    "    ch = 0xFF & cv2.waitKey()\n",
    "    if ch == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "#write simple update function to pass the trackbar position as *arg    \n",
    "def update(*arg): \n",
    "    pass\n",
    "\n",
    "#create display window for image\n",
    "cv2.namedWindow('BinaryThreshold') \n",
    "\n",
    "#read in image\n",
    "img = cv2.imread(r'images/webcam-border.png',0)\n",
    "\n",
    "#instantiate trackbar that goes in our named window and uses callback function\n",
    "cv2.createTrackbar('ThreshAdjust','BinaryThreshold',5,15,update)\n",
    "\n",
    "#initialize thresholds\n",
    "thresh1=11\n",
    "thresh2=5\n",
    "\n",
    "#loop really just runs until the escape key causes a break\n",
    "while(True):\n",
    "\n",
    "    #sets threshold 2 to trackbar position\n",
    "    thresh2=cv2.getTrackbarPos('ThreshAdjust','BinaryThreshold')   \n",
    "    #apply laplacian filter to ehance edge gradients\n",
    "    th = cv2.Laplacian(img,cv2.CV_8UC1)\n",
    "    #binarize image with adaptive threshold\n",
    "    result = cv2.adaptiveThreshold(th,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,thresh1,thresh2) \n",
    "\n",
    "    #show filtered image\n",
    "    cv2.imshow('BinaryThreshold',result)\n",
    "    #waits for escape key then breaks out of loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "\n",
    "#close our display window     \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://github.com/owainlewis/awesome-artificial-intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "http://www.kdnuggets.com/2015/06/top-20-python-machine-learning-open-source-projects.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named en",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-30f34a19aa38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# sys.path.append('~/Downloads/en') # put where you downloaded the nodebox/linguistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0men\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstanford\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named en"
     ]
    }
   ],
   "source": [
    "from nltk.parse import stanford\n",
    "from nltk import Tree\n",
    "import os\n",
    "import sys\n",
    "import getopt\n",
    "\n",
    "# sys.path.append('~/Downloads/en') # put where you downloaded the nodebox/linguistics\n",
    "\n",
    "import en\n",
    "\n",
    "from nltk.parse import stanford\n",
    "\n",
    "# Put where you downloaded the stanford-parser-full...\n",
    "os.environ['STANFORD_PARSER'] = '.' #'~/Downloads/stanford-parser-full-2015-04-20/'\n",
    "os.environ['STANFORD_MODELS'] = '.' #'~/Downloads/stanford-parser-full-2015-04-20/'\n",
    "\n",
    "smap = {}\n",
    "\n",
    "\n",
    "class Node(list):\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "        self.prev = DummyNode()\n",
    "\n",
    "    def set(self, key, value):\n",
    "        self.append((key, value))\n",
    "        if isinstance(value.prev, DummyNode):\n",
    "            value.prev = self\n",
    "\n",
    "    def get(self, key):\n",
    "        for k, v in self:\n",
    "            if key == k:\n",
    "                return v\n",
    "        return DummyNode()\n",
    "\n",
    "    def complete(self, tokens, qtype):\n",
    "        # print tokens\n",
    "        if len(tokens) == 0:\n",
    "            if qtype.lower() == \"why\":\n",
    "                cur_node = self.get('because') or self.get('since')\n",
    "                ret = [cur_node.label]\n",
    "\n",
    "                cur_node = cur_node.get('.')\n",
    "                prev_node = cur_node.prev\n",
    "                while prev_node.label not in smap:\n",
    "                    ret.append(prev_node.label)\n",
    "                    prev_node = prev_node.prev\n",
    "                ret.append(prev_node.label)\n",
    "\n",
    "                while cur_node.label not in smap and len(cur_node) > 0:\n",
    "                    ret.append(cur_node.label)\n",
    "                    cur_node = cur_node[0][1]\n",
    "                ret.append(cur_node.label)\n",
    "                return ' '.join(ret)\n",
    "\n",
    "            else:\n",
    "                if self.label in smap:\n",
    "                    return self.label\n",
    "                if not isinstance(self.get('.'), DummyNode):\n",
    "                    return self.get('.').label\n",
    "                elif len(self) > 0:\n",
    "                    return self[0][0] + \" \" + self[0][1].complete(tokens, qtype)\n",
    "                else:\n",
    "                    return \"Unsure\"\n",
    "        else:\n",
    "            token = get_word(tokens[0])\n",
    "            if tokens[0].label() in [\"VB\", \"VBD\", \"VBZ\"]:\n",
    "                token = get_root_word(token)\n",
    "            if tokens[0].label() == \"NP\":\n",
    "                return self.complete(tokens[1:], qtype)\n",
    "\n",
    "            for k, v in self:\n",
    "                if k == token:\n",
    "                    return v.complete(tokens[1:], qtype)\n",
    "            return \"Answer unclear\"\n",
    "\n",
    "    def matches(self, tokens):\n",
    "        # print tokens\n",
    "        if len(tokens) == 0:\n",
    "            return True\n",
    "\n",
    "        if tokens[0].label() == \"NP\":\n",
    "            if not isinstance(self.get('.'), DummyNode):\n",
    "                return self.get('.').matches(tokens)\n",
    "            if self.label != get_word(tokens[0]).upper():\n",
    "                return False\n",
    "            else:\n",
    "                return self.matches(tokens[1:])\n",
    "\n",
    "        token = get_word(tokens[0])\n",
    "        if tokens[0].label() in [\"VB\", \"VBD\", \"VBZ\"]:\n",
    "            token = get_root_word(token)\n",
    "\n",
    "        for k, v in self:\n",
    "            if k == token:\n",
    "                return v.matches(tokens[1:])\n",
    "        return False\n",
    "\n",
    "\n",
    "class DummyNode(Node):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.label = \"Answer unclear\"\n",
    "\n",
    "    def get(self, key):\n",
    "        return self\n",
    "\n",
    "    def __nonzero__(self):\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_word(tree):\n",
    "    if isinstance(tree, Tree):\n",
    "        words = []\n",
    "        for child in tree:\n",
    "            words.append(get_word(child))\n",
    "        return ' '.join(words)\n",
    "    else:\n",
    "        return tree\n",
    "\n",
    "\n",
    "def get_root_word(word):\n",
    "    if word in ['is', 'was']:\n",
    "        return 'is'\n",
    "    return en.verb.present(word)\n",
    "\n",
    "\n",
    "def get_node(label):\n",
    "    if label not in smap:\n",
    "        smap[label] = Node(label)\n",
    "    return smap[label]\n",
    "\n",
    "\n",
    "def flatten_tree(tree):\n",
    "    # print tree\n",
    "    if len(tree) > 0:\n",
    "        if isinstance(tree[0], Tree):\n",
    "            if isinstance(tree, Tree) and tree.label() == \"NP\":\n",
    "                return [tree]\n",
    "            tokens = []\n",
    "            for child in tree:\n",
    "                tokens += flatten_tree(child)\n",
    "            return tokens\n",
    "        else:\n",
    "            return [tree]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_tokens(tokens):\n",
    "    tokens = tokens[1:-1]\n",
    "    ret = []\n",
    "    start = 0\n",
    "    stack = 0\n",
    "    for i in xrange(len(tokens)):\n",
    "        if tokens[i] == \"(\":\n",
    "            if stack == 0:\n",
    "                start = i\n",
    "            stack += 1\n",
    "        elif tokens[i] == \")\":\n",
    "            stack -= 1\n",
    "            if stack < 0:\n",
    "                print \"Brack mismatch: \" + str(tokens)\n",
    "            if stack == 0:\n",
    "                ret.append(get_tokens(tokens[start:i + 1]))\n",
    "        else:\n",
    "            if stack == 0:\n",
    "                ret.append(tokens[i])\n",
    "    if stack != 0:\n",
    "        print \"Bracket mismatch: \" + str(tokens)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def matches(match_str, tree):\n",
    "    tokens = get_tokens(match_str.split())\n",
    "    return match_tokens(tokens, tree)\n",
    "\n",
    "\n",
    "def match_tokens(tokens, tree):\n",
    "\n",
    "    if len(tokens) == 0:\n",
    "        return True\n",
    "\n",
    "    if tokens[0] is not '.' and tree.label() not in tokens[0].split('/'):\n",
    "        return False\n",
    "\n",
    "    if tokens[-1] == '$':\n",
    "        if len(tree) != len(tokens[:-1]) - 1:\n",
    "            return False\n",
    "        else:\n",
    "            tokens = tokens[:-1]\n",
    "\n",
    "    if len(tree) < len(tokens) - 1:\n",
    "        return False\n",
    "\n",
    "    for i in xrange(len(tokens) - 1):\n",
    "        if not match_tokens(tokens[i + 1], tree[i]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Returns subject\n",
    "\n",
    "\n",
    "def describe(tree):\n",
    "\n",
    "    if not isinstance(tree, Tree):\n",
    "        print \"ERROR\"\n",
    "    if tree.label() == \"ROOT\":\n",
    "        describe(tree[0])\n",
    "        return\n",
    "\n",
    "    # Augment data\n",
    "    if matches('( S ( NP ) ( VP ( VBP ) ( ADJP ) ) )', tree):\n",
    "        _, subject = describe(tree[0])\n",
    "        action = get_root_word(get_word(tree[1][0]))\n",
    "        action_node = Node(action)\n",
    "        adj = get_word(tree[1][1])\n",
    "        adj_node = Node(adj)\n",
    "\n",
    "    # Sentences\n",
    "    if matches('( S ( NP ) ( VP ) )', tree):\n",
    "        _, subject = describe(tree[0])\n",
    "        action, action_node = describe(tree[1])\n",
    "\n",
    "        subject.set(action, action_node)\n",
    "        return action, action_node\n",
    "    if matches('( S ( VP ) )', tree):\n",
    "        return describe(tree[0])\n",
    "\n",
    "    # NOUNS\n",
    "    if matches('( NP )', tree):\n",
    "        # Ex: The dog\n",
    "        word = get_word(tree).upper()\n",
    "        return word, get_node(word)\n",
    "\n",
    "    # PROPOSITIONS\n",
    "    if matches('( PP ( . ) ( NP ) )', tree):\n",
    "        # to the mall\n",
    "        # with her parents\n",
    "        _, obj = describe(tree[1])\n",
    "        prop = get_word(tree[0])\n",
    "\n",
    "        return prop, obj\n",
    "    if matches('( PRT )', tree):\n",
    "        prt = get_word(tree)\n",
    "        return prt, Node(prt)\n",
    "\n",
    "    # VERBS\n",
    "    if matches('( VP ( VBD ) ( VP ) $ )', tree):\n",
    "        action = get_root_word(get_word(tree[0]))\n",
    "\n",
    "        return action, Node(action)\n",
    "\n",
    "    if matches('( VP ( VB/VBD ) $ )', tree):\n",
    "        action = get_root_word(get_word(tree))\n",
    "        return action, Node(action)\n",
    "\n",
    "    if matches('( VP ( VB/VBZ/VBP/VPZ/VBD/VBG/VBN ) ( PP ) )', tree):\n",
    "        action = get_root_word(get_word(tree[0]))\n",
    "        action_node = Node(action)\n",
    "        prop, prop_node = describe(tree[1])\n",
    "        action_node.set(prop, prop_node)\n",
    "        return action, action_node\n",
    "\n",
    "    if matches('( VP ( VB/VBZ/VBP/VPZ/VBD/VBG/VBN ) ( PRT ) ( NP ) )', tree):\n",
    "        action = get_root_word(get_word(tree[0]))\n",
    "        action_node = Node(action)\n",
    "        prt, prt_node = describe(tree[1])\n",
    "        action_node.set(prt, prt_node)\n",
    "        _, obj = describe(tree[2])\n",
    "        prt_node.set('.', obj)\n",
    "        return action, action_node\n",
    "\n",
    "    if matches('( VP ( VB/VBZ/VBP/VPZ/VBD/VBG/VBN ) ( NP ) )', tree):\n",
    "        action = get_root_word(get_word(tree[0]))\n",
    "        action_node = Node(action)\n",
    "\n",
    "        _, obj = describe(tree[1])\n",
    "        action_node.set('.', obj)\n",
    "\n",
    "        if matches('( VP ( VB/VBZ/VBP/VPZ/VBD/VBG/VBN ) ( NP ) ( PP ) )', tree):\n",
    "            # Assume rest is PP\n",
    "            for pp_node in tree[2:]:\n",
    "                prop, prop_node = describe(pp_node)\n",
    "                action_node.set(prop, prop_node)\n",
    "\n",
    "        if matches('( VP ( VB/VBZ/VBP/VPZ/VBD/VBG/VBN ) ( NP ) ( SBAR ) )', tree):\n",
    "            # SBAR at end\n",
    "            sbar, sbar_node = describe(tree[2])\n",
    "            action_node.set(sbar, sbar_node)\n",
    "\n",
    "\n",
    "        return action, action_node\n",
    "\n",
    "    if matches('( VP ( VB/VBZ/VBP/VPZ/VBD/VBG ) ( S ) )', tree):\n",
    "        s, s_node = describe(tree[1])\n",
    "        action = get_root_word(get_word(tree[0]))\n",
    "        action_node = Node(action)\n",
    "\n",
    "        action_node.set(s, s_node)\n",
    "        return action, action_node\n",
    "\n",
    "    if matches('( VP ( TO ) ( VP ) )', tree):\n",
    "        to_node = Node('to')\n",
    "        action, action_node = describe(tree[1])\n",
    "\n",
    "        to_node.set(action, action_node)\n",
    "\n",
    "        return 'to', to_node\n",
    "\n",
    "    if matches('( VP ( VB/VBZ/VBP/VPZ/VBD/VBG/VBN ) ( ADJP ) )', tree):\n",
    "        action = get_root_word(get_word(tree[0]))\n",
    "        action_node = Node(action)\n",
    "\n",
    "        adj = get_node(get_word(tree[1]))\n",
    "\n",
    "        action_node.set('.', adj)\n",
    "        return action, action_node\n",
    "    if matches('( VP ( VB/VBZ/VBP/VPZ/VBD/VBG/VBN ) ( SBAR ) )', tree):\n",
    "        action = get_root_word(get_word(tree[0]))\n",
    "        action_node = Node(action)\n",
    "\n",
    "        sbar, sbar_node = describe(tree[1])\n",
    "        action_node.set(sbar, sbar_node)\n",
    "        return action, action_node\n",
    "\n",
    "    # SBAR\n",
    "    if matches('( SBAR ( IN ) ( S ) )', tree):\n",
    "        prop = get_word(tree[0])\n",
    "        prop_node = Node(prop)\n",
    "        s, s_node = describe(tree[1])\n",
    "\n",
    "        prop_node.set('.', s_node)\n",
    "\n",
    "        return prop, prop_node\n",
    "\n",
    "    raise ValueError(\"ERROR reading \" + str(tree))\n",
    "\n",
    "\n",
    "def answer(tree):\n",
    "    tree = tree[0]\n",
    "    if tree.label() != \"SBARQ\":\n",
    "        print \"ERROR not a question: \" + str(tree)\n",
    "        return None\n",
    "\n",
    "    # What did Mary / Where did Mary ( ... )\n",
    "    if matches('( SBARQ ( WHNP/WHADVP ) ( SQ ( VBZ/VBD/VBP ) ( NP ) ) )', tree):\n",
    "\n",
    "        qtype = get_word(tree[0])\n",
    "        subject = get_word(tree[1][1]).upper()\n",
    "        verb = get_root_word(get_word(tree[1][0]))\n",
    "\n",
    "        if verb is 'is':\n",
    "            return get_node(subject).get('is').complete([], qtype)\n",
    "        else:\n",
    "            tokens = flatten_tree(tree[1][2:])\n",
    "            return get_node(subject).complete(tokens, qtype)\n",
    "\n",
    "    # What has blue eyes\n",
    "    if matches('( SBARQ ( WHNP ) ( SQ ( VP/VBZ ) ) )', tree):\n",
    "        tokens = flatten_tree(tree[1])\n",
    "        objs = []\n",
    "        for obj in smap:\n",
    "            if smap[obj].matches(tokens):\n",
    "                objs.append(obj)\n",
    "\n",
    "        if len(objs) == 0:\n",
    "            return \"Nothing\"\n",
    "        return ','.join(objs)\n",
    "\n",
    "    print \"ERROR answering\"\n",
    "\n",
    "def usage():\n",
    "    print \"Usage: \" + sys.argv[0] + \" [-d]\"\n",
    "\n",
    "def main(argv):\n",
    "\n",
    "    debug = False\n",
    "\n",
    "    try:\n",
    "        opts, args = getopt.getopt(argv, \"hd\",[\"help\",\"debug\"])\n",
    "    except getopt.GetoptError as e:\n",
    "        usage()\n",
    "        sys.exit(2)\n",
    "    for opt, arg in opts:\n",
    "        if opt in [\"-h\", \"help\"]:\n",
    "            usage()\n",
    "            sys.exit(2)\n",
    "        if opt in [\"-d\", \"debug\"]:\n",
    "            debug = True\n",
    "\n",
    "    parser = stanford.StanfordParser()\n",
    "\n",
    "    line = raw_input(\"Enter line: \")\n",
    "\n",
    "    while line != 'stop':\n",
    "        sent = list(parser.raw_parse(line))[0]\n",
    "        if debug:\n",
    "            print sent # print parse tree\n",
    "        if sent[0].label() == \"SBARQ\":\n",
    "            print answer(sent)\n",
    "        else:\n",
    "            try:\n",
    "                describe(sent)\n",
    "            except ValueError as e:\n",
    "                print \"Error describing sentence. \" + e\n",
    "            if debug:\n",
    "                print smap # print semantic map\n",
    "        line = raw_input(\"Enter line: \")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])\n",
    "\n",
    "# Example:\n",
    "\"\"\"\n",
    "Mary went sledding\n",
    "Where did Mary go? sledding\n",
    "The boy played soccer with a ball\n",
    "What did the boy play? soccer\n",
    "What did the boy play soccer with? a ball\n",
    "Mary went to the mall\n",
    "Where did Mary go? to the mall\n",
    "Where did Mary go to? the mall\n",
    "Mary likes eating peanuts\n",
    "What does Mary like eating? peanuts\n",
    "What does Mary like? eating peanuts\n",
    "Mary likes to eat peanuts\n",
    "What does Mary like? To eat peanuts\n",
    "What does Mary like to eat? peanuts\n",
    "Mark likes to smoke\n",
    "What does Mary like? to smoke\n",
    "Blueberries are blue\n",
    "What color are blueberries? blue\n",
    "James ran because James was scared\n",
    "Why did James run? because James was scared\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "https://github.com/berlius/artificial-intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "https://github.com/BotCube/awesome-bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "https://gitlab.idiap.ch/groups/bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "https://github.com/wayaai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "http://www.dmoztools.net/Computers/Artificial_Intelligence/Machine_Learning/Software/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "http://www.clips.ua.ac.be/pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#WORKING FINE\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def callback(x):\n",
    "    pass\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "ilowH = 0\n",
    "ihighH = 179\n",
    "\n",
    "ilowS = 0\n",
    "ihighS = 255\n",
    "\n",
    "ilowV = 0\n",
    "ihighV = 255\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('lowH','image',ilowH,179,callback)\n",
    "cv2.createTrackbar('highH','image',ihighH,179,callback)\n",
    "\n",
    "cv2.createTrackbar('lowS','image',ilowS,255,callback)\n",
    "cv2.createTrackbar('highS','image',ihighS,255,callback)\n",
    "\n",
    "cv2.createTrackbar('lowV','image',ilowV,255,callback)\n",
    "cv2.createTrackbar('highV','image',ihighV,255,callback)\n",
    "\n",
    "\n",
    "\n",
    "while(1):\n",
    "    # get current positions of four trackbars\n",
    "    lH = cv2.getTrackbarPos('lowH','image')\n",
    "    hH = cv2.getTrackbarPos('highH','image')\n",
    "    lS = cv2.getTrackbarPos('lowS','image')\n",
    "    hS = cv2.getTrackbarPos('highS','image')\n",
    "    lV = cv2.getTrackbarPos('lowV','image')\n",
    "    hV = cv2.getTrackbarPos('highV','image')\n",
    "    \n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    cv2.imshow('hsv', hsv)\n",
    "    lower_hsv = np.array([lH, lS, lV])\n",
    "    higher_hsv = np.array([hH, hS, hV])\n",
    "    mask = cv2.inRange(hsv, lower_hsv, higher_hsv)\n",
    "    cv2.imshow('mask', mask)\n",
    "    cv2.imshow('frame', frame)\n",
    "    #print ilowH, ilowS, ilowV\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizing Filter\n",
    "import cv2 as cv\n",
    "img = cv2.imread('images/webcam-border.png')\n",
    "#img = cv.imread(path)\n",
    "newImage = img.copy()\n",
    "newImage = cv.resize(newImage, (600, 600))\n",
    "nim = cv.normalize(newImage, newImage, 20, 200, cv.NORM_MINMAX)\n",
    "cv.imshow('orig', img)\n",
    "cv.imshow('dst_rt', nim)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "https://medium.com/technology-invention-and-more/how-to-build-a-simple-neural-network-in-9-lines-of-python-code-cc8f23647ca1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99993704]\n"
     ]
    }
   ],
   "source": [
    "from numpy import exp, array, random, dot\n",
    "training_set_inputs = array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
    "training_set_outputs = array([[0, 1, 1, 0]]).T\n",
    "random.seed(1)\n",
    "synaptic_weights = 2 * random.random((3, 1)) - 1\n",
    "for iteration in xrange(10000):\n",
    "    output = 1 / (1 + exp(-(dot(training_set_inputs, synaptic_weights))))\n",
    "    synaptic_weights += dot(training_set_inputs.T, (training_set_outputs - output) * output * (1 - output))\n",
    "print 1 / (1 + exp(-(dot(array([1, 0, 0]), synaptic_weights))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random starting synaptic weights: \n",
      "[[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n",
      "New synaptic weights after training: \n",
      "[[ 9.67299303]\n",
      " [-0.2078435 ]\n",
      " [-4.62963669]]\n",
      "Considering new situation [1, 0, 0] -> ?: \n",
      "[ 0.99993704]\n"
     ]
    }
   ],
   "source": [
    "from numpy import exp, array, random, dot\n",
    "\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self):\n",
    "        # Seed the random number generator, so it generates the same numbers\n",
    "        # every time the program runs.\n",
    "        random.seed(1)\n",
    "\n",
    "        # We model a single neuron, with 3 input connections and 1 output connection.\n",
    "        # We assign random weights to a 3 x 1 matrix, with values in the range -1 to 1\n",
    "        # and mean 0.\n",
    "        self.synaptic_weights = 2 * random.random((3, 1)) - 1\n",
    "\n",
    "    # The Sigmoid function, which describes an S shaped curve.\n",
    "    # We pass the weighted sum of the inputs through this function to\n",
    "    # normalise them between 0 and 1.\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + exp(-x))\n",
    "\n",
    "    # The derivative of the Sigmoid function.\n",
    "    # This is the gradient of the Sigmoid curve.\n",
    "    # It indicates how confident we are about the existing weight.\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    # We train the neural network through a process of trial and error.\n",
    "    # Adjusting the synaptic weights each time.\n",
    "    def train(self, training_set_inputs, training_set_outputs, number_of_training_iterations):\n",
    "        for iteration in xrange(number_of_training_iterations):\n",
    "            # Pass the training set through our neural network (a single neuron).\n",
    "            output = self.think(training_set_inputs)\n",
    "\n",
    "            # Calculate the error (The difference between the desired output\n",
    "            # and the predicted output).\n",
    "            error = training_set_outputs - output\n",
    "\n",
    "            # Multiply the error by the input and again by the gradient of the Sigmoid curve.\n",
    "            # This means less confident weights are adjusted more.\n",
    "            # This means inputs, which are zero, do not cause changes to the weights.\n",
    "            adjustment = dot(training_set_inputs.T, error * self.__sigmoid_derivative(output))\n",
    "\n",
    "            # Adjust the weights.\n",
    "            self.synaptic_weights += adjustment\n",
    "\n",
    "    # The neural network thinks.\n",
    "    def think(self, inputs):\n",
    "        # Pass inputs through our neural network (our single neuron).\n",
    "        return self.__sigmoid(dot(inputs, self.synaptic_weights))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #Intialise a single neuron neural network.\n",
    "    neural_network = NeuralNetwork()\n",
    "\n",
    "    print \"Random starting synaptic weights: \"\n",
    "    print neural_network.synaptic_weights\n",
    "\n",
    "    # The training set. We have 4 examples, each consisting of 3 input values\n",
    "    # and 1 output value.\n",
    "    training_set_inputs = array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
    "    training_set_outputs = array([[0, 1, 1, 0]]).T\n",
    "\n",
    "    # Train the neural network using a training set.\n",
    "    # Do it 10,000 times and make small adjustments each time.\n",
    "    neural_network.train(training_set_inputs, training_set_outputs, 10000)\n",
    "\n",
    "    print \"New synaptic weights after training: \"\n",
    "    print neural_network.synaptic_weights\n",
    "\n",
    "    # Test the neural network with a new situation.\n",
    "    print \"Considering new situation [1, 0, 0] -> ?: \"\n",
    "    print neural_network.think(array([1, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
